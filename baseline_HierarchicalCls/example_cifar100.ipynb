{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxl173430/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed is set: 42\n",
      "Using PyTorch version: 1.13.0\n",
      "use gpu indexed: 0\n",
      "Loading TinyImageNet...\n",
      "length of parent_to_subclass:  107\n",
      "Total 29 Candidate superclasses: ['n04371563', 'n03419014', 'n04490091', 'n02924116', 'n02858304', 'n04379243', 'n07557434', 'n07611358', 'n07707451', 'n03748162', 'n03259505', 'n02898711', 'n03743902', 'n02796623', 'n09433442', 'n03278248', 'n04438304', 'n04147495', 'n04565375', 'n03880531', 'n02876657', 'n01767661', 'n01772222', 'n01942177', 'n02470325', 'n02370806', 'n02075296', 'n02121808', 'n01844917']\n",
      "Vague classes: ['n02876657', 'n02924116', 'n04371563', 'n01942177', 'n07707451', 'n07611358', 'n02370806', 'n02858304', 'n02121808', 'n04147495']\n",
      "Vague classes nid: [['n02823428', 'n03983396'], ['n04146614', 'n04487081'], ['n02837789', 'n04371430'], ['n01944390', 'n01945685', 'n01950731'], ['n07734744', 'n07715103'], ['n07614500', 'n07615774'], ['n02395406', 'n02410509'], ['n03447447', 'n03662601'], ['n02123045', 'n02123394', 'n02124075'], ['n02666196', 'n02841315']]\n",
      "Vague classes ids: [[73, 135], [145, 166], [74, 158], [15, 16, 17], [185, 183], [179, 180], [48, 50], [108, 115], [30, 31, 32], [59, 75]]\n",
      "Actual label sets\n",
      " R: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167], [168], [169], [170], [171], [172], [173], [174], [175], [176], [177], [178], [179], [180], [181], [182], [183], [184], [185], [186], [187], [188], [189], [190], [191], [192], [193], [194], [195], [196], [197], [198], [199], [73, 135], [145, 166], [74, 158], [15, 16, 17], [185, 183], [179, 180], [48, 50], [108, 115], [30, 31, 32], [59, 75]]\n",
      "Data splitted. Train, Valid, Test size: (90000, 10000, 10000)\n",
      "Loading data finished. Time: 0m 15s\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/\"\n",
    "sys.path.insert(1, data_path)\n",
    "\n",
    "from data.tinyImageNet import tinyImageNetVague\n",
    "from data.cifar100 import CIFAR100Vague\n",
    "from common_tools import set_device, create_path, dictToObj, set_random_seeds\n",
    "\n",
    "set_random_seeds(42)\n",
    "gpu = 0\n",
    "device = set_device(gpu)\n",
    "\n",
    "data_dir = '/home/cxl173430/data/DATASETS/'\n",
    "batch_size = 64\n",
    "num_comp = 10\n",
    "gauss_kernel_size = 3\n",
    "\n",
    "\n",
    "# mydata = CIFAR100Vague(\n",
    "#                     data_dir, \n",
    "#                     num_comp=num_comp,\n",
    "#                     batch_size=batch_size,\n",
    "#                     duplicate=False,\n",
    "#                     blur=True,\n",
    "#                     gauss_kernel_size=gauss_kernel_size,\n",
    "#                     pretrain=False,\n",
    "#                     num_workers=4,\n",
    "#                     seed=42,\n",
    "#                     comp_el_size=2,\n",
    "#                     )\n",
    "\n",
    "mydata = tinyImageNetVague(\n",
    "            data_dir, \n",
    "            num_comp=num_comp, \n",
    "            batch_size=batch_size,\n",
    "            imagenet_hierarchy_path=data_dir,\n",
    "            blur=True,\n",
    "            gray=False,\n",
    "            gauss_kernel_size=gauss_kernel_size,\n",
    "            pretrain=True,\n",
    "            num_workers=4,\n",
    "            seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def generate_data_label(mydata, split='train'):\n",
    "    if split == 'train':\n",
    "        data_tuple = mydata.train_loader.dataset\n",
    "    elif split == 'test':\n",
    "        data_tuple = mydata.test_loader.dataset\n",
    "    \n",
    "    data = []\n",
    "    label_GT = []\n",
    "    label_comp = []\n",
    "    num_data = len(data_tuple)\n",
    "    for i in range(num_data):\n",
    "        data.append(data_tuple[i][0])\n",
    "        label_GT.append(data_tuple[i][1])\n",
    "        label_comp.append(data_tuple[i][2])\n",
    "    data = torch.stack(data, dim=0) # 4500,3,32,32\n",
    "    # data = data.reshape(num_data, -1)\n",
    "    # print(data.shape) # 4500,3072\n",
    "\n",
    "    ### labels\n",
    "    labels = []\n",
    "    for i in range(num_data):\n",
    "        if label_GT[i] != label_comp[i]:\n",
    "            tmp = [label_comp[i], '']\n",
    "        else:\n",
    "            tmp = [label_comp[i], label_GT[i]]\n",
    "            # tmp = ['rest', train_label_GT[i]]\n",
    "        labels.append(tmp)\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = generate_data_label(mydata, split='train')\n",
    "test_data, test_labels = generate_data_label(mydata, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90000, 3, 224, 224])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cxl173430/anaconda3/envs/HENN/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['100' '']\n",
      " ['107' '']\n",
      " ['103' '']\n",
      " ...\n",
      " ['101' '']\n",
      " ['100' '']\n",
      " ['108' '']]\n"
     ]
    }
   ],
   "source": [
    "from hiclass import LocalClassifierPerNode\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_data_a = train_data.reshape(len(train_data), -1)\n",
    "train_data_a=train_data_a.numpy()\n",
    "\n",
    "X_train = train_data_a[-4000:]\n",
    "Y_train = train_labels[-4000:]\n",
    "\n",
    "X_test = test_data\n",
    "# Use random forest classifiers for every node\n",
    "# rf = RandomForestClassifier()\n",
    "rf = LogisticRegression()\n",
    "classifier = LocalClassifierPerNode(local_classifier=rf)\n",
    "\n",
    "# Train local classifier per node\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = classifier.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, labels, num_singles, R):\n",
    "    correct_vague = 0.0\n",
    "    correct_nonvague = 0.0\n",
    "    vague_total = 0\n",
    "    nonvague_total = 0\n",
    "    num_corr = 0\n",
    "    for i in range(len(predictions)):\n",
    "        # singleton acc\n",
    "        if predictions[i][1]: # singleton prediction\n",
    "            if int(predictions[i][1]) == labels[i][1]:\n",
    "                num_corr += 1\n",
    "\n",
    "        # composite \n",
    "        if predictions[i][0]: # composite prediction\n",
    "            predicted_set = set(R[int(predictions[i][0])])\n",
    "            k = labels[i][0] # ground truth\n",
    "            ground_truth_set = set(R[k])\n",
    "            intersect = predicted_set.intersection(ground_truth_set)\n",
    "            union = predicted_set.union(ground_truth_set)\n",
    "            rate = len(intersect) / len(union)\n",
    "            if int(predictions[i][0])>=num_singles:\n",
    "                correct_vague += rate\n",
    "                vague_total += 1\n",
    "            else:\n",
    "                correct_nonvague += 1\n",
    "                nonvague_total += 1\n",
    "    stat_result = [correct_nonvague, correct_vague, nonvague_total,vague_total]\n",
    "\n",
    "    overall_js = (stat_result[0] + stat_result[1])/(len(predictions)+1e-10)\n",
    "    avg_js_vague = stat_result[1] / (stat_result[3]+1e-10)\n",
    "    acc = num_corr / len(predictions)\n",
    "    return overall_js, avg_js_vague, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "33\n",
      "72\n",
      "51\n",
      "71\n",
      "92\n",
      "15\n",
      "14\n",
      "23\n",
      "0\n",
      "71\n",
      "75\n",
      "81\n",
      "69\n",
      "40\n",
      "43\n",
      "97\n",
      "70\n",
      "53\n",
      "70\n",
      "49\n",
      "75\n",
      "29\n",
      "21\n",
      "16\n",
      "39\n",
      "8\n",
      "8\n",
      "70\n",
      "20\n",
      "61\n",
      "41\n",
      "93\n",
      "56\n",
      "73\n",
      "58\n",
      "11\n",
      "25\n",
      "37\n",
      "63\n",
      "24\n",
      "49\n",
      "73\n",
      "56\n",
      "22\n",
      "41\n",
      "58\n",
      "75\n",
      "17\n",
      "4\n",
      "9\n",
      "57\n",
      "2\n",
      "32\n",
      "71\n",
      "52\n",
      "42\n",
      "69\n",
      "77\n",
      "27\n",
      "15\n",
      "65\n",
      "35\n",
      "43\n",
      "82\n",
      "63\n",
      "66\n",
      "90\n",
      "91\n",
      "32\n",
      "32\n",
      "10\n",
      "77\n",
      "22\n",
      "71\n",
      "78\n",
      "54\n",
      "6\n",
      "29\n",
      "89\n",
      "78\n",
      "33\n",
      "11\n",
      "22\n",
      "18\n",
      "27\n",
      "21\n",
      "13\n",
      "21\n",
      "50\n",
      "75\n",
      "37\n",
      "35\n",
      "26\n",
      "83\n",
      "47\n",
      "95\n",
      "43\n",
      "69\n",
      "76\n",
      "17\n",
      "57\n",
      "59\n",
      "25\n",
      "20\n",
      "27\n",
      "0\n",
      "9\n",
      "71\n",
      "8\n",
      "43\n",
      "57\n",
      "56\n",
      "85\n",
      "10\n",
      "19\n",
      "92\n",
      "33\n",
      "20\n",
      "21\n",
      "50\n",
      "70\n",
      "46\n",
      "11\n",
      "16\n",
      "1\n",
      "74\n",
      "33\n",
      "60\n",
      "64\n",
      "52\n",
      "23\n",
      "4\n",
      "11\n",
      "52\n",
      "37\n",
      "24\n",
      "25\n",
      "39\n",
      "51\n",
      "58\n",
      "58\n",
      "77\n",
      "18\n",
      "45\n",
      "66\n",
      "58\n",
      "20\n",
      "24\n",
      "4\n",
      "36\n",
      "8\n",
      "87\n",
      "10\n",
      "30\n",
      "47\n",
      "54\n",
      "99\n",
      "51\n",
      "83\n",
      "37\n",
      "4\n",
      "83\n",
      "95\n",
      "83\n",
      "32\n",
      "73\n",
      "18\n",
      "40\n",
      "39\n",
      "64\n",
      "22\n",
      "28\n",
      "40\n",
      "98\n",
      "83\n",
      "12\n",
      "24\n",
      "45\n",
      "13\n",
      "94\n",
      "24\n",
      "58\n",
      "63\n",
      "7\n",
      "87\n",
      "78\n",
      "68\n",
      "60\n",
      "6\n",
      "23\n",
      "44\n",
      "93\n",
      "73\n",
      "98\n",
      "49\n",
      "90\n",
      "97\n",
      "2\n",
      "67\n",
      "16\n",
      "81\n",
      "94\n",
      "27\n",
      "76\n",
      "77\n",
      "12\n",
      "18\n",
      "0\n",
      "76\n",
      "79\n",
      "71\n",
      "89\n",
      "57\n",
      "47\n",
      "24\n",
      "65\n",
      "0\n",
      "32\n",
      "36\n",
      "82\n",
      "23\n",
      "24\n",
      "34\n",
      "21\n",
      "11\n",
      "53\n",
      "80\n",
      "44\n",
      "4\n",
      "39\n",
      "91\n",
      "16\n",
      "36\n",
      "68\n",
      "50\n",
      "97\n",
      "58\n",
      "31\n",
      "6\n",
      "42\n",
      "80\n",
      "76\n",
      "89\n",
      "55\n",
      "91\n",
      "70\n",
      "1\n",
      "62\n",
      "99\n",
      "51\n",
      "96\n",
      "83\n",
      "42\n",
      "18\n",
      "66\n",
      "40\n",
      "62\n",
      "78\n",
      "84\n",
      "28\n",
      "89\n",
      "30\n",
      "66\n",
      "18\n",
      "38\n",
      "42\n",
      "92\n",
      "27\n",
      "11\n",
      "86\n",
      "44\n",
      "96\n",
      "12\n",
      "16\n",
      "67\n",
      "43\n",
      "89\n",
      "96\n",
      "12\n",
      "40\n",
      "7\n",
      "86\n",
      "77\n",
      "76\n",
      "31\n",
      "18\n",
      "28\n",
      "19\n",
      "18\n",
      "41\n",
      "42\n",
      "43\n",
      "93\n",
      "15\n",
      "10\n",
      "8\n",
      "37\n",
      "89\n",
      "32\n",
      "67\n",
      "12\n",
      "2\n",
      "91\n",
      "94\n",
      "7\n",
      "71\n",
      "36\n",
      "61\n",
      "62\n",
      "5\n",
      "60\n",
      "45\n",
      "34\n",
      "40\n",
      "68\n",
      "62\n",
      "99\n",
      "66\n",
      "46\n",
      "7\n",
      "10\n",
      "10\n",
      "68\n",
      "34\n",
      "37\n",
      "58\n",
      "48\n",
      "40\n",
      "96\n",
      "14\n",
      "11\n",
      "66\n",
      "64\n",
      "39\n",
      "33\n",
      "94\n",
      "63\n",
      "10\n",
      "89\n",
      "92\n",
      "90\n",
      "65\n",
      "90\n",
      "28\n",
      "29\n",
      "87\n",
      "86\n",
      "7\n",
      "0\n",
      "94\n",
      "11\n",
      "26\n",
      "41\n",
      "21\n",
      "69\n",
      "27\n",
      "29\n",
      "67\n",
      "85\n",
      "65\n",
      "40\n",
      "57\n",
      "72\n",
      "30\n",
      "74\n",
      "27\n",
      "3\n",
      "49\n",
      "52\n",
      "95\n",
      "40\n",
      "93\n",
      "77\n",
      "6\n",
      "57\n",
      "72\n",
      "16\n",
      "98\n",
      "89\n",
      "40\n",
      "96\n",
      "71\n",
      "3\n",
      "2\n",
      "66\n",
      "27\n",
      "8\n",
      "53\n",
      "33\n",
      "55\n",
      "81\n",
      "88\n",
      "96\n",
      "68\n",
      "42\n",
      "77\n",
      "10\n",
      "27\n",
      "32\n",
      "79\n",
      "98\n",
      "18\n",
      "51\n",
      "2\n",
      "19\n",
      "36\n",
      "10\n",
      "16\n",
      "5\n",
      "81\n",
      "85\n",
      "26\n",
      "85\n",
      "65\n",
      "22\n",
      "55\n",
      "85\n",
      "22\n",
      "22\n",
      "10\n",
      "18\n",
      "98\n",
      "9\n",
      "26\n",
      "27\n",
      "7\n",
      "5\n",
      "58\n",
      "87\n",
      "76\n",
      "2\n",
      "54\n",
      "38\n",
      "33\n",
      "17\n",
      "6\n",
      "0\n",
      "79\n",
      "97\n",
      "14\n",
      "14\n",
      "73\n",
      "79\n",
      "8\n",
      "42\n",
      "4\n",
      "25\n",
      "37\n",
      "75\n",
      "74\n",
      "41\n",
      "0\n",
      "99\n",
      "79\n",
      "87\n",
      "67\n",
      "72\n",
      "38\n",
      "25\n",
      "49\n",
      "3\n",
      "74\n",
      "69\n",
      "36\n",
      "77\n",
      "89\n",
      "71\n",
      "31\n",
      "90\n",
      "11\n",
      "2\n",
      "41\n",
      "38\n",
      "58\n",
      "47\n",
      "93\n",
      "68\n",
      "11\n",
      "35\n",
      "67\n",
      "54\n",
      "53\n",
      "30\n",
      "36\n",
      "83\n",
      "54\n",
      "64\n",
      "46\n",
      "45\n",
      "98\n",
      "62\n",
      "46\n",
      "88\n",
      "37\n",
      "18\n",
      "29\n",
      "63\n",
      "8\n",
      "33\n",
      "35\n",
      "6\n",
      "76\n",
      "19\n",
      "99\n",
      "53\n",
      "15\n",
      "57\n",
      "2\n",
      "27\n",
      "27\n",
      "93\n",
      "81\n",
      "54\n",
      "71\n",
      "26\n",
      "25\n",
      "35\n",
      "30\n",
      "72\n",
      "8\n",
      "62\n",
      "78\n",
      "47\n",
      "73\n",
      "43\n",
      "20\n",
      "83\n",
      "63\n",
      "49\n",
      "28\n",
      "26\n",
      "45\n",
      "36\n",
      "36\n",
      "68\n",
      "1\n",
      "2\n",
      "99\n",
      "65\n",
      "38\n",
      "58\n",
      "96\n",
      "38\n",
      "87\n",
      "82\n",
      "22\n",
      "83\n",
      "41\n",
      "7\n",
      "12\n",
      "10\n",
      "35\n",
      "44\n",
      "81\n",
      "91\n",
      "9\n",
      "24\n",
      "3\n",
      "30\n",
      "1\n",
      "39\n",
      "98\n",
      "72\n",
      "83\n",
      "80\n",
      "43\n",
      "84\n",
      "66\n",
      "4\n",
      "64\n",
      "77\n",
      "98\n",
      "82\n",
      "81\n",
      "20\n",
      "0\n",
      "48\n",
      "46\n",
      "22\n",
      "13\n",
      "17\n",
      "39\n",
      "76\n",
      "0\n",
      "17\n",
      "64\n",
      "48\n",
      "90\n",
      "93\n",
      "75\n",
      "96\n",
      "97\n",
      "83\n",
      "60\n",
      "61\n",
      "32\n",
      "26\n",
      "84\n",
      "41\n",
      "12\n",
      "85\n",
      "12\n",
      "8\n",
      "82\n",
      "72\n",
      "94\n",
      "22\n",
      "15\n",
      "66\n",
      "89\n",
      "97\n",
      "19\n",
      "0\n",
      "5\n",
      "36\n",
      "45\n",
      "1\n",
      "94\n",
      "66\n",
      "86\n",
      "17\n",
      "64\n",
      "99\n",
      "34\n",
      "30\n",
      "73\n",
      "83\n",
      "1\n",
      "28\n",
      "77\n",
      "74\n",
      "68\n",
      "14\n",
      "14\n",
      "1\n",
      "97\n",
      "45\n",
      "21\n",
      "37\n",
      "32\n",
      "73\n",
      "88\n",
      "86\n",
      "92\n",
      "14\n",
      "86\n",
      "74\n",
      "25\n",
      "93\n",
      "78\n",
      "77\n",
      "88\n",
      "42\n",
      "10\n",
      "65\n",
      "26\n",
      "85\n",
      "78\n",
      "29\n",
      "32\n",
      "81\n",
      "97\n",
      "1\n",
      "0\n",
      "21\n",
      "15\n",
      "57\n",
      "97\n",
      "76\n",
      "60\n",
      "87\n",
      "46\n",
      "1\n",
      "61\n",
      "75\n",
      "62\n",
      "21\n",
      "61\n",
      "78\n",
      "90\n",
      "68\n",
      "94\n",
      "88\n",
      "95\n",
      "83\n",
      "32\n",
      "93\n",
      "77\n",
      "38\n",
      "63\n",
      "61\n",
      "41\n",
      "88\n",
      "83\n",
      "35\n",
      "82\n",
      "50\n",
      "15\n",
      "48\n",
      "25\n",
      "4\n",
      "71\n",
      "8\n",
      "98\n",
      "67\n",
      "7\n",
      "85\n",
      "25\n",
      "96\n",
      "60\n",
      "55\n",
      "80\n",
      "13\n",
      "90\n",
      "54\n",
      "15\n",
      "76\n",
      "39\n",
      "95\n",
      "24\n",
      "64\n",
      "70\n",
      "88\n",
      "81\n",
      "0\n",
      "12\n",
      "64\n",
      "79\n",
      "86\n",
      "60\n",
      "22\n",
      "38\n",
      "14\n",
      "48\n",
      "33\n",
      "55\n",
      "53\n",
      "40\n",
      "1\n",
      "58\n",
      "94\n",
      "70\n",
      "29\n",
      "86\n",
      "23\n",
      "46\n",
      "58\n",
      "99\n",
      "78\n",
      "10\n",
      "53\n",
      "37\n",
      "97\n",
      "65\n",
      "15\n",
      "77\n",
      "52\n",
      "63\n",
      "32\n",
      "36\n",
      "7\n",
      "36\n",
      "74\n",
      "13\n",
      "22\n",
      "32\n",
      "54\n",
      "62\n",
      "84\n",
      "57\n",
      "25\n",
      "11\n",
      "62\n",
      "85\n",
      "26\n",
      "16\n",
      "96\n",
      "71\n",
      "90\n",
      "39\n",
      "20\n",
      "47\n",
      "35\n",
      "19\n",
      "52\n",
      "66\n",
      "32\n",
      "53\n",
      "53\n",
      "21\n",
      "98\n",
      "6\n",
      "88\n",
      "71\n",
      "45\n",
      "98\n",
      "55\n",
      "99\n",
      "24\n",
      "93\n",
      "67\n",
      "16\n",
      "33\n",
      "9\n",
      "10\n",
      "46\n",
      "68\n",
      "24\n",
      "96\n",
      "22\n",
      "40\n",
      "63\n",
      "53\n",
      "10\n",
      "14\n",
      "41\n",
      "77\n",
      "54\n",
      "84\n",
      "20\n",
      "29\n",
      "76\n",
      "36\n",
      "1\n",
      "26\n",
      "99\n",
      "2\n",
      "96\n",
      "69\n",
      "36\n",
      "18\n",
      "90\n",
      "66\n",
      "52\n",
      "37\n",
      "99\n",
      "97\n",
      "12\n",
      "55\n",
      "15\n",
      "85\n",
      "15\n",
      "16\n",
      "99\n",
      "80\n",
      "28\n",
      "69\n",
      "51\n",
      "72\n",
      "39\n",
      "8\n",
      "15\n",
      "21\n",
      "77\n",
      "45\n",
      "21\n",
      "80\n",
      "89\n",
      "37\n",
      "48\n",
      "47\n",
      "56\n",
      "65\n",
      "96\n",
      "14\n",
      "52\n",
      "2\n",
      "60\n",
      "68\n",
      "22\n",
      "44\n",
      "19\n",
      "54\n",
      "97\n",
      "23\n",
      "54\n",
      "62\n",
      "56\n",
      "42\n",
      "81\n",
      "66\n",
      "87\n",
      "47\n",
      "47\n",
      "45\n",
      "42\n",
      "51\n",
      "10\n",
      "35\n",
      "68\n",
      "13\n",
      "55\n",
      "34\n",
      "74\n",
      "47\n",
      "40\n",
      "51\n",
      "6\n",
      "3\n",
      "76\n",
      "52\n",
      "53\n",
      "34\n",
      "60\n",
      "63\n",
      "24\n",
      "36\n",
      "69\n",
      "82\n",
      "90\n",
      "70\n",
      "75\n",
      "77\n",
      "43\n",
      "43\n",
      "78\n",
      "81\n",
      "66\n",
      "35\n",
      "84\n",
      "21\n",
      "49\n",
      "96\n",
      "15\n",
      "37\n",
      "2\n",
      "89\n",
      "36\n",
      "9\n",
      "53\n",
      "65\n",
      "67\n",
      "94\n",
      "40\n",
      "72\n",
      "90\n",
      "86\n",
      "85\n",
      "30\n",
      "25\n",
      "60\n",
      "2\n",
      "29\n",
      "0\n",
      "9\n",
      "37\n",
      "1\n",
      "50\n",
      "90\n",
      "27\n",
      "52\n",
      "36\n",
      "48\n",
      "71\n",
      "12\n",
      "97\n",
      "0\n",
      "3\n",
      "41\n",
      "21\n",
      "16\n",
      "51\n",
      "72\n",
      "13\n",
      "63\n",
      "81\n",
      "73\n",
      "55\n",
      "30\n",
      "28\n",
      "10\n",
      "84\n",
      "8\n",
      "9\n",
      "93\n",
      "2\n",
      "78\n",
      "26\n",
      "16\n",
      "17\n",
      "39\n",
      "20\n",
      "3\n",
      "81\n",
      "26\n",
      "96\n",
      "45\n",
      "15\n",
      "29\n",
      "57\n",
      "60\n",
      "49\n",
      "36\n",
      "23\n",
      "63\n",
      "72\n",
      "19\n",
      "41\n",
      "55\n",
      "26\n",
      "25\n",
      "49\n",
      "28\n",
      "20\n",
      "33\n",
      "7\n",
      "45\n",
      "7\n",
      "89\n",
      "1\n",
      "90\n",
      "42\n",
      "15\n",
      "93\n",
      "96\n",
      "59\n",
      "29\n",
      "29\n",
      "75\n",
      "93\n",
      "8\n",
      "70\n",
      "48\n",
      "82\n",
      "84\n",
      "81\n",
      "72\n",
      "38\n",
      "63\n",
      "76\n",
      "4\n",
      "54\n",
      "60\n",
      "1\n",
      "49\n",
      "1\n",
      "77\n",
      "30\n",
      "98\n",
      "62\n",
      "25\n",
      "26\n",
      "55\n",
      "25\n",
      "21\n",
      "25\n",
      "82\n",
      "80\n",
      "93\n",
      "35\n",
      "61\n",
      "81\n",
      "69\n",
      "91\n",
      "96\n",
      "34\n",
      "0\n",
      "28\n",
      "51\n",
      "65\n",
      "5\n",
      "13\n",
      "52\n",
      "58\n",
      "65\n",
      "32\n",
      "37\n",
      "63\n",
      "61\n",
      "19\n",
      "2\n",
      "49\n",
      "64\n",
      "58\n",
      "93\n",
      "62\n",
      "52\n",
      "53\n",
      "41\n",
      "33\n",
      "84\n",
      "22\n",
      "67\n",
      "44\n",
      "95\n",
      "24\n",
      "46\n",
      "98\n",
      "31\n",
      "83\n",
      "16\n",
      "2\n",
      "47\n",
      "51\n",
      "3\n",
      "18\n",
      "60\n",
      "38\n",
      "89\n",
      "11\n",
      "63\n",
      "15\n",
      "49\n",
      "63\n",
      "85\n",
      "12\n",
      "38\n",
      "66\n",
      "99\n",
      "72\n",
      "83\n",
      "12\n",
      "93\n",
      "51\n",
      "21\n",
      "47\n",
      "21\n",
      "43\n",
      "77\n",
      "55\n",
      "36\n",
      "57\n",
      "69\n",
      "5\n",
      "29\n",
      "41\n",
      "14\n",
      "41\n",
      "77\n",
      "58\n",
      "60\n",
      "45\n",
      "88\n",
      "19\n",
      "48\n",
      "5\n",
      "81\n",
      "69\n",
      "77\n",
      "60\n",
      "88\n",
      "92\n",
      "31\n",
      "34\n",
      "36\n",
      "30\n",
      "64\n",
      "82\n",
      "88\n",
      "7\n",
      "38\n",
      "57\n",
      "92\n",
      "11\n",
      "41\n",
      "38\n",
      "90\n",
      "76\n",
      "28\n",
      "24\n",
      "84\n",
      "76\n",
      "88\n",
      "98\n",
      "96\n",
      "93\n",
      "64\n",
      "45\n",
      "54\n",
      "26\n",
      "79\n",
      "70\n",
      "46\n",
      "89\n",
      "89\n",
      "64\n",
      "93\n",
      "39\n",
      "53\n",
      "36\n",
      "50\n",
      "56\n",
      "84\n",
      "46\n",
      "13\n",
      "5\n",
      "51\n",
      "5\n",
      "68\n",
      "70\n",
      "92\n",
      "93\n",
      "18\n",
      "37\n",
      "50\n",
      "81\n",
      "67\n",
      "41\n",
      "35\n",
      "99\n",
      "41\n",
      "79\n",
      "90\n",
      "59\n",
      "35\n",
      "16\n",
      "17\n",
      "64\n",
      "90\n",
      "96\n",
      "3\n",
      "88\n",
      "45\n",
      "0\n",
      "68\n",
      "49\n",
      "0\n",
      "18\n",
      "22\n",
      "72\n",
      "4\n",
      "66\n",
      "5\n",
      "46\n",
      "79\n",
      "70\n",
      "49\n",
      "34\n",
      "48\n",
      "71\n",
      "37\n",
      "6\n",
      "91\n",
      "58\n",
      "42\n",
      "17\n",
      "1\n",
      "5\n",
      "65\n",
      "5\n",
      "38\n",
      "47\n",
      "38\n",
      "63\n",
      "61\n",
      "28\n",
      "99\n",
      "20\n",
      "88\n",
      "50\n",
      "53\n",
      "97\n",
      "78\n",
      "35\n",
      "50\n",
      "6\n",
      "98\n",
      "65\n",
      "68\n",
      "26\n",
      "96\n",
      "17\n",
      "65\n",
      "47\n",
      "12\n",
      "94\n",
      "81\n",
      "76\n",
      "91\n",
      "72\n",
      "35\n",
      "18\n",
      "96\n",
      "92\n",
      "98\n",
      "0\n",
      "43\n",
      "43\n",
      "44\n",
      "73\n",
      "53\n",
      "37\n",
      "8\n",
      "25\n",
      "52\n",
      "29\n",
      "44\n",
      "12\n",
      "38\n",
      "5\n",
      "25\n",
      "41\n",
      "81\n",
      "23\n",
      "68\n",
      "81\n",
      "43\n",
      "8\n",
      "11\n",
      "18\n",
      "5\n",
      "34\n",
      "48\n",
      "25\n",
      "31\n",
      "8\n",
      "88\n",
      "10\n",
      "76\n",
      "95\n",
      "94\n",
      "83\n",
      "52\n",
      "44\n",
      "16\n",
      "99\n",
      "68\n",
      "28\n",
      "15\n",
      "47\n",
      "34\n",
      "57\n",
      "13\n",
      "22\n",
      "9\n",
      "90\n",
      "50\n",
      "34\n",
      "43\n",
      "20\n",
      "87\n",
      "91\n",
      "80\n",
      "9\n",
      "17\n",
      "57\n",
      "14\n",
      "27\n",
      "46\n",
      "13\n",
      "44\n",
      "24\n",
      "10\n",
      "84\n",
      "4\n",
      "56\n",
      "29\n",
      "29\n",
      "51\n",
      "78\n",
      "62\n",
      "53\n",
      "17\n",
      "28\n",
      "28\n",
      "11\n",
      "65\n",
      "48\n",
      "48\n",
      "12\n",
      "55\n",
      "66\n",
      "98\n",
      "8\n",
      "94\n",
      "25\n",
      "70\n",
      "54\n",
      "12\n",
      "86\n",
      "3\n",
      "76\n",
      "13\n",
      "2\n",
      "55\n",
      "45\n",
      "51\n",
      "53\n",
      "28\n",
      "9\n",
      "87\n",
      "13\n",
      "30\n",
      "58\n",
      "61\n",
      "70\n",
      "39\n",
      "47\n",
      "34\n",
      "26\n",
      "50\n",
      "64\n",
      "37\n",
      "92\n",
      "14\n",
      "26\n",
      "37\n",
      "94\n",
      "29\n",
      "15\n",
      "63\n",
      "7\n",
      "32\n",
      "9\n",
      "43\n",
      "12\n",
      "27\n",
      "78\n",
      "97\n",
      "55\n",
      "11\n",
      "69\n",
      "66\n",
      "20\n",
      "54\n",
      "45\n",
      "86\n",
      "84\n",
      "55\n",
      "6\n",
      "54\n",
      "69\n",
      "47\n",
      "62\n",
      "57\n",
      "85\n",
      "30\n",
      "16\n",
      "11\n",
      "82\n",
      "65\n",
      "81\n",
      "39\n",
      "79\n",
      "25\n",
      "44\n",
      "16\n",
      "23\n",
      "17\n",
      "49\n",
      "69\n",
      "74\n",
      "63\n",
      "10\n",
      "56\n",
      "43\n",
      "22\n",
      "11\n",
      "9\n",
      "17\n",
      "31\n",
      "52\n",
      "52\n",
      "36\n",
      "58\n",
      "79\n",
      "42\n",
      "32\n",
      "15\n",
      "15\n",
      "79\n",
      "56\n",
      "77\n",
      "57\n",
      "5\n",
      "76\n",
      "84\n",
      "47\n",
      "79\n",
      "64\n",
      "3\n",
      "22\n",
      "84\n",
      "15\n",
      "83\n",
      "64\n",
      "61\n",
      "16\n",
      "76\n",
      "96\n",
      "87\n",
      "39\n",
      "60\n",
      "74\n",
      "27\n",
      "68\n",
      "7\n",
      "23\n",
      "42\n",
      "47\n",
      "2\n",
      "20\n",
      "24\n",
      "17\n",
      "12\n",
      "55\n",
      "13\n",
      "17\n",
      "67\n",
      "21\n",
      "21\n",
      "46\n",
      "79\n",
      "21\n",
      "61\n",
      "64\n",
      "41\n",
      "16\n",
      "40\n",
      "54\n",
      "70\n",
      "65\n",
      "84\n",
      "64\n",
      "37\n",
      "92\n",
      "71\n",
      "17\n",
      "96\n",
      "94\n",
      "39\n",
      "93\n",
      "79\n",
      "34\n",
      "26\n",
      "24\n",
      "12\n",
      "53\n",
      "88\n",
      "20\n",
      "47\n",
      "98\n",
      "25\n",
      "45\n",
      "25\n",
      "61\n",
      "68\n",
      "27\n",
      "13\n",
      "92\n",
      "12\n",
      "46\n",
      "76\n",
      "67\n",
      "27\n",
      "2\n",
      "78\n",
      "48\n",
      "98\n",
      "20\n",
      "8\n",
      "43\n",
      "57\n",
      "63\n",
      "7\n",
      "10\n",
      "47\n",
      "46\n",
      "52\n",
      "90\n",
      "69\n",
      "78\n",
      "15\n",
      "78\n",
      "29\n",
      "61\n",
      "5\n",
      "30\n",
      "86\n",
      "85\n",
      "10\n",
      "44\n",
      "34\n",
      "24\n",
      "56\n",
      "61\n",
      "62\n",
      "38\n",
      "72\n",
      "44\n",
      "53\n",
      "7\n",
      "38\n",
      "17\n",
      "40\n",
      "91\n",
      "83\n",
      "82\n",
      "10\n",
      "21\n",
      "30\n",
      "65\n",
      "47\n",
      "57\n",
      "16\n",
      "81\n",
      "30\n",
      "72\n",
      "96\n",
      "88\n",
      "62\n",
      "95\n",
      "27\n",
      "61\n",
      "2\n",
      "21\n",
      "87\n",
      "5\n",
      "69\n",
      "37\n",
      "0\n",
      "78\n",
      "20\n",
      "85\n",
      "54\n",
      "53\n",
      "73\n",
      "69\n",
      "3\n",
      "35\n",
      "49\n",
      "33\n",
      "73\n",
      "99\n",
      "97\n",
      "89\n",
      "3\n",
      "54\n",
      "90\n",
      "45\n",
      "11\n",
      "1\n",
      "51\n",
      "28\n",
      "79\n",
      "47\n",
      "54\n",
      "83\n",
      "40\n",
      "14\n",
      "26\n",
      "27\n",
      "12\n",
      "44\n",
      "29\n",
      "59\n",
      "8\n",
      "17\n",
      "56\n",
      "46\n",
      "80\n",
      "1\n",
      "82\n",
      "51\n",
      "34\n",
      "86\n",
      "96\n",
      "86\n",
      "93\n",
      "38\n",
      "20\n",
      "19\n",
      "2\n",
      "20\n",
      "91\n",
      "55\n",
      "65\n",
      "64\n",
      "90\n",
      "70\n",
      "34\n",
      "11\n",
      "55\n",
      "68\n",
      "52\n",
      "79\n",
      "22\n",
      "22\n",
      "86\n",
      "10\n",
      "1\n",
      "75\n",
      "48\n",
      "5\n",
      "90\n",
      "99\n",
      "33\n",
      "82\n",
      "76\n",
      "51\n",
      "92\n",
      "65\n",
      "77\n",
      "70\n",
      "12\n",
      "91\n",
      "83\n",
      "95\n",
      "48\n",
      "52\n",
      "30\n",
      "49\n",
      "11\n",
      "3\n",
      "17\n",
      "94\n",
      "29\n",
      "87\n",
      "49\n",
      "64\n",
      "57\n",
      "95\n",
      "28\n",
      "16\n",
      "99\n",
      "46\n",
      "31\n",
      "25\n",
      "2\n",
      "95\n",
      "21\n",
      "83\n",
      "56\n",
      "17\n",
      "53\n",
      "71\n",
      "7\n",
      "94\n",
      "53\n",
      "89\n",
      "10\n",
      "7\n",
      "36\n",
      "79\n",
      "53\n",
      "87\n",
      "43\n",
      "76\n",
      "69\n",
      "22\n",
      "17\n",
      "53\n",
      "68\n",
      "44\n",
      "89\n",
      "15\n",
      "45\n",
      "95\n",
      "37\n",
      "28\n",
      "13\n",
      "52\n",
      "24\n",
      "21\n",
      "55\n",
      "99\n",
      "98\n",
      "21\n",
      "81\n",
      "88\n",
      "93\n",
      "61\n",
      "17\n",
      "44\n",
      "49\n",
      "81\n",
      "78\n",
      "94\n",
      "40\n",
      "60\n",
      "58\n",
      "4\n",
      "88\n",
      "18\n",
      "24\n",
      "36\n",
      "26\n",
      "74\n",
      "88\n",
      "65\n",
      "0\n",
      "43\n",
      "22\n",
      "47\n",
      "65\n",
      "22\n",
      "69\n",
      "78\n",
      "4\n",
      "69\n",
      "46\n",
      "97\n",
      "29\n",
      "18\n",
      "64\n",
      "98\n",
      "65\n",
      "36\n",
      "94\n",
      "84\n",
      "91\n",
      "20\n",
      "36\n",
      "50\n",
      "76\n",
      "29\n",
      "63\n",
      "6\n",
      "30\n",
      "99\n",
      "55\n",
      "21\n",
      "38\n",
      "83\n",
      "31\n",
      "49\n",
      "39\n",
      "66\n",
      "66\n",
      "53\n",
      "54\n",
      "41\n",
      "36\n",
      "61\n",
      "88\n",
      "30\n",
      "19\n",
      "41\n",
      "89\n",
      "46\n",
      "78\n",
      "37\n",
      "31\n",
      "22\n",
      "2\n",
      "78\n",
      "13\n",
      "73\n",
      "51\n",
      "95\n",
      "2\n",
      "38\n",
      "98\n",
      "18\n",
      "42\n",
      "7\n",
      "88\n",
      "61\n",
      "12\n",
      "8\n",
      "92\n",
      "41\n",
      "33\n",
      "65\n",
      "17\n",
      "51\n",
      "99\n",
      "35\n",
      "67\n",
      "63\n",
      "63\n",
      "58\n",
      "96\n",
      "77\n",
      "1\n",
      "36\n",
      "53\n",
      "83\n",
      "13\n",
      "98\n",
      "21\n",
      "35\n",
      "39\n",
      "49\n",
      "81\n",
      "35\n",
      "3\n",
      "77\n",
      "89\n",
      "30\n",
      "85\n",
      "48\n",
      "98\n",
      "38\n",
      "80\n",
      "39\n",
      "43\n",
      "12\n",
      "21\n",
      "18\n",
      "25\n",
      "5\n",
      "25\n",
      "63\n",
      "78\n",
      "40\n",
      "29\n",
      "15\n",
      "39\n",
      "49\n",
      "93\n",
      "39\n",
      "77\n",
      "69\n",
      "53\n",
      "64\n",
      "12\n",
      "57\n",
      "5\n",
      "17\n",
      "97\n",
      "37\n",
      "48\n",
      "79\n",
      "5\n",
      "83\n",
      "16\n",
      "41\n",
      "48\n",
      "54\n",
      "79\n",
      "67\n",
      "73\n",
      "0\n",
      "14\n",
      "29\n",
      "84\n",
      "48\n",
      "36\n",
      "76\n",
      "95\n",
      "20\n",
      "59\n",
      "57\n",
      "67\n",
      "6\n",
      "71\n",
      "21\n",
      "7\n",
      "91\n",
      "92\n",
      "87\n",
      "91\n",
      "16\n",
      "86\n",
      "58\n",
      "89\n",
      "97\n",
      "83\n",
      "72\n",
      "85\n",
      "41\n",
      "3\n",
      "20\n",
      "10\n",
      "74\n",
      "49\n",
      "63\n",
      "56\n",
      "64\n",
      "11\n",
      "41\n",
      "81\n",
      "90\n",
      "89\n",
      "86\n",
      "22\n",
      "41\n",
      "27\n",
      "87\n",
      "21\n",
      "34\n",
      "36\n",
      "90\n",
      "94\n",
      "71\n",
      "62\n",
      "95\n",
      "38\n",
      "41\n",
      "24\n",
      "89\n",
      "15\n",
      "81\n",
      "8\n",
      "48\n",
      "30\n",
      "52\n",
      "79\n",
      "20\n",
      "68\n",
      "16\n",
      "78\n",
      "45\n",
      "66\n",
      "52\n",
      "43\n",
      "20\n",
      "98\n",
      "24\n",
      "71\n",
      "49\n",
      "44\n",
      "46\n",
      "62\n",
      "22\n",
      "11\n",
      "89\n",
      "99\n",
      "73\n",
      "26\n",
      "53\n",
      "10\n",
      "41\n",
      "12\n",
      "2\n",
      "39\n",
      "19\n",
      "74\n",
      "79\n",
      "73\n",
      "46\n",
      "3\n",
      "22\n",
      "6\n",
      "59\n",
      "54\n",
      "87\n",
      "2\n",
      "87\n",
      "49\n",
      "91\n",
      "37\n",
      "53\n",
      "51\n",
      "7\n",
      "99\n",
      "13\n",
      "25\n",
      "66\n",
      "80\n",
      "22\n",
      "73\n",
      "83\n",
      "14\n",
      "42\n",
      "86\n",
      "22\n",
      "90\n",
      "74\n",
      "24\n",
      "84\n",
      "91\n",
      "97\n",
      "88\n",
      "4\n",
      "26\n",
      "22\n",
      "19\n",
      "67\n",
      "73\n",
      "84\n",
      "98\n",
      "35\n",
      "29\n",
      "51\n",
      "59\n",
      "62\n",
      "60\n",
      "68\n",
      "44\n",
      "83\n",
      "0\n",
      "41\n",
      "90\n",
      "48\n",
      "82\n",
      "67\n",
      "28\n",
      "71\n",
      "79\n",
      "43\n",
      "17\n",
      "5\n",
      "17\n",
      "7\n",
      "84\n",
      "57\n",
      "27\n",
      "57\n",
      "68\n",
      "26\n",
      "59\n",
      "87\n",
      "99\n",
      "3\n",
      "66\n",
      "38\n",
      "15\n",
      "75\n",
      "20\n",
      "47\n",
      "0\n",
      "14\n",
      "85\n",
      "62\n",
      "55\n",
      "63\n",
      "69\n",
      "77\n",
      "73\n",
      "38\n",
      "52\n",
      "84\n",
      "37\n",
      "60\n",
      "21\n",
      "96\n",
      "68\n",
      "16\n",
      "19\n",
      "40\n",
      "70\n",
      "61\n",
      "10\n",
      "57\n",
      "81\n",
      "68\n",
      "12\n",
      "10\n",
      "38\n",
      "10\n",
      "47\n",
      "76\n",
      "11\n",
      "72\n",
      "1\n",
      "14\n",
      "30\n",
      "93\n",
      "54\n",
      "15\n",
      "2\n",
      "26\n",
      "65\n",
      "32\n",
      "12\n",
      "58\n",
      "73\n",
      "76\n",
      "95\n",
      "26\n",
      "92\n",
      "47\n",
      "84\n",
      "29\n",
      "51\n",
      "44\n",
      "45\n",
      "60\n",
      "34\n",
      "97\n",
      "1\n",
      "93\n",
      "97\n",
      "19\n",
      "19\n",
      "69\n",
      "65\n",
      "78\n",
      "5\n",
      "34\n",
      "76\n",
      "25\n",
      "50\n",
      "30\n",
      "69\n",
      "59\n",
      "34\n",
      "77\n",
      "46\n",
      "66\n",
      "73\n",
      "87\n",
      "90\n",
      "18\n",
      "6\n",
      "38\n",
      "81\n",
      "25\n",
      "81\n",
      "64\n",
      "70\n",
      "37\n",
      "76\n",
      "31\n",
      "0\n",
      "90\n",
      "32\n",
      "5\n",
      "41\n",
      "80\n",
      "5\n",
      "52\n",
      "51\n",
      "25\n",
      "20\n",
      "61\n",
      "98\n",
      "20\n",
      "32\n",
      "35\n",
      "5\n",
      "72\n",
      "61\n",
      "43\n",
      "58\n",
      "36\n",
      "99\n",
      "60\n",
      "70\n",
      "38\n",
      "59\n",
      "26\n",
      "78\n",
      "83\n",
      "23\n",
      "52\n",
      "32\n",
      "54\n",
      "61\n",
      "49\n",
      "53\n",
      "15\n",
      "12\n",
      "86\n",
      "55\n",
      "58\n",
      "5\n",
      "30\n",
      "26\n",
      "10\n",
      "0\n",
      "11\n",
      "9\n",
      "53\n",
      "33\n",
      "94\n",
      "46\n",
      "99\n",
      "34\n",
      "1\n",
      "17\n",
      "63\n",
      "69\n",
      "66\n",
      "37\n",
      "40\n",
      "93\n",
      "24\n",
      "82\n",
      "23\n",
      "30\n",
      "66\n",
      "30\n",
      "11\n",
      "11\n",
      "94\n",
      "88\n",
      "37\n",
      "29\n",
      "46\n",
      "95\n",
      "54\n",
      "41\n",
      "6\n",
      "19\n",
      "22\n",
      "3\n",
      "32\n",
      "55\n",
      "53\n",
      "72\n",
      "33\n",
      "20\n",
      "63\n",
      "12\n",
      "64\n",
      "23\n",
      "22\n",
      "75\n",
      "8\n",
      "33\n",
      "66\n",
      "55\n",
      "72\n",
      "73\n",
      "84\n",
      "13\n",
      "96\n",
      "65\n",
      "22\n",
      "0\n",
      "19\n",
      "80\n",
      "23\n",
      "85\n",
      "68\n",
      "86\n",
      "37\n",
      "81\n",
      "35\n",
      "98\n",
      "8\n",
      "23\n",
      "76\n",
      "74\n",
      "89\n",
      "60\n",
      "69\n",
      "96\n",
      "32\n",
      "29\n",
      "64\n",
      "9\n",
      "16\n",
      "0\n",
      "74\n",
      "17\n",
      "54\n",
      "62\n",
      "6\n",
      "34\n",
      "65\n",
      "8\n",
      "46\n",
      "67\n",
      "53\n",
      "23\n",
      "78\n",
      "61\n",
      "26\n",
      "64\n",
      "25\n",
      "70\n",
      "96\n",
      "67\n",
      "22\n",
      "45\n",
      "65\n",
      "96\n",
      "79\n",
      "23\n",
      "76\n",
      "26\n",
      "57\n",
      "16\n",
      "64\n",
      "34\n",
      "82\n",
      "66\n",
      "83\n",
      "72\n",
      "71\n",
      "9\n",
      "60\n",
      "35\n",
      "43\n",
      "29\n",
      "93\n",
      "58\n",
      "94\n",
      "5\n",
      "83\n",
      "92\n",
      "26\n",
      "39\n",
      "86\n",
      "93\n",
      "16\n",
      "85\n",
      "27\n",
      "76\n",
      "89\n",
      "18\n",
      "14\n",
      "73\n",
      "71\n",
      "20\n",
      "20\n",
      "16\n",
      "51\n",
      "88\n",
      "5\n",
      "25\n",
      "64\n",
      "77\n",
      "22\n",
      "3\n",
      "68\n",
      "28\n",
      "44\n",
      "13\n",
      "73\n",
      "98\n",
      "52\n",
      "44\n",
      "99\n",
      "17\n",
      "31\n",
      "50\n",
      "87\n",
      "44\n",
      "85\n",
      "58\n",
      "57\n",
      "45\n",
      "28\n",
      "5\n",
      "11\n",
      "81\n",
      "46\n",
      "96\n",
      "69\n",
      "19\n",
      "55\n",
      "75\n",
      "31\n",
      "97\n",
      "66\n",
      "51\n",
      "71\n",
      "29\n",
      "4\n",
      "89\n",
      "99\n",
      "39\n",
      "52\n",
      "59\n",
      "12\n",
      "96\n",
      "16\n",
      "36\n",
      "64\n",
      "27\n",
      "81\n",
      "37\n",
      "11\n",
      "85\n",
      "35\n",
      "78\n",
      "72\n",
      "70\n",
      "74\n",
      "42\n",
      "0\n",
      "41\n",
      "39\n",
      "87\n",
      "80\n",
      "44\n",
      "47\n",
      "95\n",
      "10\n",
      "21\n",
      "63\n",
      "55\n",
      "69\n",
      "20\n",
      "85\n",
      "78\n",
      "23\n",
      "13\n",
      "92\n",
      "98\n",
      "84\n",
      "75\n",
      "10\n",
      "4\n",
      "52\n",
      "55\n",
      "61\n",
      "89\n",
      "57\n",
      "50\n",
      "42\n",
      "40\n",
      "88\n",
      "73\n",
      "49\n",
      "20\n",
      "2\n",
      "16\n",
      "26\n",
      "91\n",
      "88\n",
      "85\n",
      "28\n",
      "27\n",
      "83\n",
      "54\n",
      "65\n",
      "71\n",
      "77\n",
      "13\n",
      "56\n",
      "76\n",
      "37\n",
      "72\n",
      "63\n",
      "46\n",
      "75\n",
      "90\n",
      "26\n",
      "60\n",
      "49\n",
      "50\n",
      "15\n",
      "2\n",
      "78\n",
      "94\n",
      "86\n",
      "25\n",
      "11\n",
      "13\n",
      "40\n",
      "47\n",
      "44\n",
      "90\n",
      "95\n",
      "78\n",
      "78\n",
      "39\n",
      "40\n",
      "69\n",
      "72\n",
      "64\n",
      "47\n",
      "60\n",
      "78\n",
      "36\n",
      "75\n",
      "36\n",
      "82\n",
      "88\n",
      "38\n",
      "36\n",
      "81\n",
      "72\n",
      "50\n",
      "2\n",
      "52\n",
      "68\n",
      "44\n",
      "6\n",
      "53\n",
      "56\n",
      "32\n",
      "46\n",
      "34\n",
      "83\n",
      "74\n",
      "43\n",
      "77\n",
      "87\n",
      "26\n",
      "63\n",
      "5\n",
      "79\n",
      "85\n",
      "38\n",
      "80\n",
      "59\n",
      "5\n",
      "73\n",
      "32\n",
      "15\n",
      "24\n",
      "93\n",
      "2\n",
      "88\n",
      "49\n",
      "11\n",
      "38\n",
      "62\n",
      "7\n",
      "6\n",
      "61\n",
      "27\n",
      "5\n",
      "41\n",
      "37\n",
      "10\n",
      "43\n",
      "69\n",
      "21\n",
      "73\n",
      "68\n",
      "88\n",
      "10\n",
      "65\n",
      "47\n",
      "20\n",
      "35\n",
      "2\n",
      "88\n",
      "83\n",
      "72\n",
      "60\n",
      "82\n",
      "61\n",
      "68\n",
      "92\n",
      "22\n",
      "84\n",
      "87\n",
      "32\n",
      "91\n",
      "38\n",
      "36\n",
      "9\n",
      "63\n",
      "57\n",
      "50\n",
      "97\n",
      "27\n",
      "34\n",
      "69\n",
      "1\n",
      "82\n",
      "13\n",
      "84\n",
      "15\n",
      "97\n",
      "22\n",
      "27\n",
      "18\n",
      "79\n",
      "98\n",
      "74\n",
      "97\n",
      "13\n",
      "78\n",
      "88\n",
      "98\n",
      "78\n",
      "5\n",
      "4\n",
      "17\n",
      "60\n",
      "44\n",
      "69\n",
      "53\n",
      "37\n",
      "44\n",
      "3\n",
      "24\n",
      "27\n",
      "38\n",
      "35\n",
      "21\n",
      "0\n",
      "16\n",
      "84\n",
      "11\n",
      "41\n",
      "98\n",
      "89\n",
      "99\n",
      "31\n",
      "46\n",
      "68\n",
      "47\n",
      "47\n",
      "11\n",
      "70\n",
      "23\n",
      "58\n",
      "27\n",
      "8\n",
      "47\n",
      "27\n",
      "68\n",
      "53\n",
      "34\n",
      "68\n",
      "96\n",
      "53\n",
      "19\n",
      "70\n",
      "21\n",
      "90\n",
      "11\n",
      "21\n",
      "4\n",
      "1\n",
      "53\n",
      "29\n",
      "93\n",
      "14\n",
      "71\n",
      "88\n",
      "98\n",
      "89\n",
      "27\n",
      "71\n",
      "64\n",
      "94\n",
      "61\n",
      "20\n",
      "83\n",
      "38\n",
      "99\n",
      "5\n",
      "11\n",
      "84\n",
      "88\n",
      "6\n",
      "5\n",
      "31\n",
      "65\n",
      "59\n",
      "30\n",
      "97\n",
      "64\n",
      "46\n",
      "22\n",
      "51\n",
      "25\n",
      "18\n",
      "78\n",
      "56\n",
      "88\n",
      "24\n",
      "5\n",
      "22\n",
      "15\n",
      "67\n",
      "15\n",
      "2\n",
      "60\n",
      "41\n",
      "11\n",
      "70\n",
      "76\n",
      "81\n",
      "89\n",
      "24\n",
      "30\n",
      "0\n",
      "75\n",
      "63\n",
      "9\n",
      "36\n",
      "20\n",
      "7\n",
      "74\n",
      "24\n",
      "73\n",
      "32\n",
      "35\n",
      "87\n",
      "31\n",
      "14\n",
      "73\n",
      "47\n",
      "65\n",
      "77\n",
      "51\n",
      "61\n",
      "30\n",
      "32\n",
      "66\n",
      "29\n",
      "97\n",
      "16\n",
      "0\n",
      "82\n",
      "43\n",
      "23\n",
      "89\n",
      "16\n",
      "68\n",
      "2\n",
      "45\n",
      "44\n",
      "23\n",
      "38\n",
      "40\n",
      "35\n",
      "73\n",
      "0\n",
      "88\n",
      "7\n",
      "42\n",
      "77\n",
      "9\n",
      "35\n",
      "96\n",
      "83\n",
      "94\n",
      "3\n",
      "90\n",
      "75\n",
      "38\n",
      "14\n",
      "71\n",
      "36\n",
      "3\n",
      "78\n",
      "21\n",
      "13\n",
      "48\n",
      "83\n",
      "50\n",
      "79\n",
      "55\n",
      "21\n",
      "60\n",
      "8\n",
      "84\n",
      "92\n",
      "6\n",
      "51\n",
      "25\n",
      "27\n",
      "86\n",
      "27\n",
      "8\n",
      "21\n",
      "12\n",
      "44\n",
      "75\n",
      "27\n",
      "50\n",
      "80\n",
      "54\n",
      "94\n",
      "48\n",
      "41\n",
      "53\n",
      "14\n",
      "55\n",
      "53\n",
      "12\n",
      "7\n",
      "46\n",
      "95\n",
      "38\n",
      "67\n",
      "0\n",
      "72\n",
      "11\n",
      "27\n",
      "1\n",
      "73\n",
      "25\n",
      "47\n",
      "42\n",
      "75\n",
      "81\n",
      "69\n",
      "10\n",
      "24\n",
      "87\n",
      "35\n",
      "69\n",
      "86\n",
      "59\n",
      "84\n",
      "63\n",
      "86\n",
      "82\n",
      "14\n",
      "10\n",
      "26\n",
      "62\n",
      "10\n",
      "17\n",
      "76\n",
      "56\n",
      "63\n",
      "85\n",
      "99\n",
      "64\n",
      "7\n",
      "24\n",
      "13\n",
      "6\n",
      "37\n",
      "16\n",
      "33\n",
      "48\n",
      "44\n",
      "80\n",
      "46\n",
      "86\n",
      "3\n",
      "57\n",
      "54\n",
      "43\n",
      "35\n",
      "93\n",
      "62\n",
      "88\n",
      "64\n",
      "78\n",
      "45\n",
      "36\n",
      "1\n",
      "43\n",
      "34\n",
      "71\n",
      "87\n",
      "39\n",
      "18\n",
      "57\n",
      "67\n",
      "4\n",
      "73\n",
      "41\n",
      "76\n",
      "73\n",
      "43\n",
      "94\n",
      "25\n",
      "63\n",
      "71\n",
      "15\n",
      "52\n",
      "38\n",
      "30\n",
      "64\n",
      "30\n",
      "23\n",
      "35\n",
      "74\n",
      "36\n",
      "76\n",
      "96\n",
      "17\n",
      "31\n",
      "76\n",
      "88\n",
      "63\n",
      "2\n",
      "77\n",
      "49\n",
      "92\n",
      "17\n",
      "89\n",
      "3\n",
      "88\n",
      "26\n",
      "41\n",
      "79\n",
      "32\n",
      "62\n",
      "55\n",
      "20\n",
      "98\n",
      "26\n",
      "17\n",
      "1\n",
      "32\n",
      "43\n",
      "85\n",
      "72\n",
      "59\n",
      "24\n",
      "13\n",
      "14\n",
      "42\n",
      "40\n",
      "33\n",
      "20\n",
      "68\n",
      "23\n",
      "62\n",
      "24\n",
      "55\n",
      "10\n",
      "22\n",
      "70\n",
      "79\n",
      "73\n",
      "45\n",
      "84\n",
      "9\n",
      "70\n",
      "96\n",
      "97\n",
      "33\n",
      "67\n",
      "21\n",
      "90\n",
      "62\n",
      "57\n",
      "25\n",
      "54\n",
      "69\n",
      "40\n",
      "41\n",
      "93\n",
      "9\n",
      "83\n",
      "7\n",
      "25\n",
      "13\n",
      "90\n",
      "16\n",
      "12\n",
      "48\n",
      "50\n",
      "37\n",
      "49\n",
      "60\n",
      "36\n",
      "37\n",
      "39\n",
      "65\n",
      "91\n",
      "70\n",
      "90\n",
      "99\n",
      "10\n",
      "4\n",
      "21\n",
      "48\n",
      "36\n",
      "66\n",
      "5\n",
      "93\n",
      "60\n",
      "93\n",
      "28\n",
      "49\n",
      "32\n",
      "79\n",
      "98\n",
      "86\n",
      "30\n",
      "64\n",
      "18\n",
      "44\n",
      "13\n",
      "99\n",
      "27\n",
      "69\n",
      "87\n",
      "6\n",
      "22\n",
      "50\n",
      "90\n",
      "71\n",
      "20\n",
      "91\n",
      "90\n",
      "71\n",
      "49\n",
      "42\n",
      "57\n",
      "20\n",
      "63\n",
      "67\n",
      "12\n",
      "39\n",
      "20\n",
      "73\n",
      "52\n",
      "69\n",
      "56\n",
      "10\n",
      "51\n",
      "44\n",
      "62\n",
      "62\n",
      "43\n",
      "30\n",
      "99\n",
      "35\n",
      "79\n",
      "35\n",
      "9\n",
      "20\n",
      "79\n",
      "15\n",
      "87\n",
      "37\n",
      "20\n",
      "60\n",
      "33\n",
      "92\n",
      "73\n",
      "88\n",
      "38\n",
      "90\n",
      "70\n",
      "77\n",
      "84\n",
      "16\n",
      "18\n",
      "51\n",
      "42\n",
      "68\n",
      "18\n",
      "24\n",
      "57\n",
      "21\n",
      "42\n",
      "39\n",
      "10\n",
      "20\n",
      "9\n",
      "4\n",
      "51\n",
      "1\n",
      "14\n",
      "53\n",
      "60\n",
      "53\n",
      "90\n",
      "43\n",
      "62\n",
      "38\n",
      "76\n",
      "84\n",
      "46\n",
      "32\n",
      "54\n",
      "34\n",
      "29\n",
      "65\n",
      "72\n",
      "65\n",
      "10\n",
      "25\n",
      "48\n",
      "90\n",
      "94\n",
      "4\n",
      "55\n",
      "99\n",
      "68\n",
      "6\n",
      "24\n",
      "82\n",
      "43\n",
      "71\n",
      "75\n",
      "26\n",
      "49\n",
      "98\n",
      "25\n",
      "62\n",
      "73\n",
      "2\n",
      "81\n",
      "99\n",
      "11\n",
      "31\n",
      "82\n",
      "56\n",
      "3\n",
      "88\n",
      "62\n",
      "8\n",
      "73\n",
      "20\n",
      "44\n",
      "89\n",
      "0\n",
      "16\n",
      "96\n",
      "24\n",
      "26\n",
      "93\n",
      "6\n",
      "53\n",
      "93\n",
      "19\n",
      "49\n",
      "11\n",
      "45\n",
      "27\n",
      "26\n",
      "84\n",
      "1\n",
      "26\n",
      "57\n",
      "60\n",
      "18\n",
      "55\n",
      "71\n",
      "56\n",
      "47\n",
      "21\n",
      "36\n",
      "9\n",
      "41\n",
      "24\n",
      "75\n",
      "5\n",
      "32\n",
      "12\n",
      "57\n",
      "84\n",
      "76\n",
      "65\n",
      "12\n",
      "21\n",
      "76\n",
      "29\n",
      "57\n",
      "75\n",
      "32\n",
      "25\n",
      "96\n",
      "56\n",
      "49\n",
      "8\n",
      "19\n",
      "98\n",
      "39\n",
      "71\n",
      "46\n",
      "3\n",
      "41\n",
      "64\n",
      "37\n",
      "8\n",
      "13\n",
      "99\n",
      "31\n",
      "35\n",
      "52\n",
      "73\n",
      "89\n",
      "2\n",
      "54\n",
      "97\n",
      "73\n",
      "95\n",
      "1\n",
      "12\n",
      "0\n",
      "51\n",
      "73\n",
      "72\n",
      "83\n",
      "74\n",
      "1\n",
      "12\n",
      "38\n",
      "51\n",
      "29\n",
      "77\n",
      "44\n",
      "18\n",
      "10\n",
      "16\n",
      "43\n",
      "0\n",
      "70\n",
      "17\n",
      "3\n",
      "6\n",
      "83\n",
      "65\n",
      "0\n",
      "46\n",
      "85\n",
      "62\n",
      "18\n",
      "81\n",
      "40\n",
      "48\n",
      "2\n",
      "21\n",
      "24\n",
      "95\n",
      "53\n",
      "89\n",
      "50\n",
      "35\n",
      "98\n",
      "32\n",
      "58\n",
      "97\n",
      "56\n",
      "78\n",
      "60\n",
      "79\n",
      "84\n",
      "28\n",
      "46\n",
      "90\n",
      "43\n",
      "9\n",
      "42\n",
      "84\n",
      "27\n",
      "17\n",
      "62\n",
      "23\n",
      "31\n",
      "11\n",
      "48\n",
      "82\n",
      "87\n",
      "14\n",
      "99\n",
      "13\n",
      "66\n",
      "35\n",
      "42\n",
      "20\n",
      "2\n",
      "16\n",
      "68\n",
      "93\n",
      "79\n",
      "87\n",
      "41\n",
      "2\n",
      "96\n",
      "39\n",
      "49\n",
      "57\n",
      "96\n",
      "12\n",
      "38\n",
      "65\n",
      "39\n",
      "93\n",
      "83\n",
      "32\n",
      "19\n",
      "8\n",
      "53\n",
      "69\n",
      "72\n",
      "23\n",
      "29\n",
      "43\n",
      "88\n",
      "11\n",
      "96\n",
      "62\n",
      "54\n",
      "2\n",
      "73\n",
      "34\n",
      "48\n",
      "34\n",
      "34\n",
      "94\n",
      "88\n",
      "71\n",
      "97\n",
      "7\n",
      "35\n",
      "77\n",
      "95\n",
      "44\n",
      "45\n",
      "27\n",
      "80\n",
      "84\n",
      "99\n",
      "52\n",
      "92\n",
      "70\n",
      "16\n",
      "88\n",
      "25\n",
      "58\n",
      "79\n",
      "54\n",
      "73\n",
      "50\n",
      "47\n",
      "51\n",
      "78\n",
      "26\n",
      "17\n",
      "86\n",
      "72\n",
      "87\n",
      "34\n",
      "47\n",
      "25\n",
      "72\n",
      "29\n",
      "95\n",
      "86\n",
      "92\n",
      "78\n",
      "3\n",
      "28\n",
      "58\n",
      "66\n",
      "78\n",
      "38\n",
      "22\n",
      "66\n",
      "95\n",
      "45\n",
      "97\n",
      "65\n",
      "54\n",
      "71\n",
      "70\n",
      "80\n",
      "85\n",
      "28\n",
      "41\n",
      "71\n",
      "64\n",
      "75\n",
      "90\n",
      "7\n",
      "37\n",
      "23\n",
      "54\n",
      "84\n",
      "86\n",
      "8\n",
      "22\n",
      "51\n",
      "75\n",
      "26\n",
      "11\n",
      "46\n",
      "64\n",
      "92\n",
      "55\n",
      "39\n",
      "66\n",
      "86\n",
      "85\n",
      "0\n",
      "8\n",
      "27\n",
      "57\n",
      "13\n",
      "94\n",
      "40\n",
      "61\n",
      "94\n",
      "17\n",
      "11\n",
      "1\n",
      "4\n",
      "49\n",
      "77\n",
      "0\n",
      "1\n",
      "80\n",
      "48\n",
      "39\n",
      "55\n",
      "38\n",
      "12\n",
      "35\n",
      "12\n",
      "78\n",
      "87\n",
      "11\n",
      "0\n",
      "90\n",
      "10\n",
      "88\n",
      "10\n",
      "97\n",
      "48\n",
      "63\n",
      "51\n",
      "52\n",
      "47\n",
      "85\n",
      "69\n",
      "65\n",
      "81\n",
      "30\n",
      "51\n",
      "69\n",
      "28\n",
      "4\n",
      "31\n",
      "97\n",
      "48\n",
      "64\n",
      "80\n",
      "0\n",
      "0\n",
      "5\n",
      "45\n",
      "13\n",
      "90\n",
      "85\n",
      "51\n",
      "34\n",
      "44\n",
      "91\n",
      "85\n",
      "56\n",
      "10\n",
      "46\n",
      "93\n",
      "77\n",
      "81\n",
      "18\n",
      "66\n",
      "49\n",
      "0\n",
      "70\n",
      "63\n",
      "99\n",
      "14\n",
      "5\n",
      "26\n",
      "24\n",
      "86\n",
      "64\n",
      "55\n",
      "1\n",
      "94\n",
      "74\n",
      "6\n",
      "25\n",
      "52\n",
      "90\n",
      "5\n",
      "40\n",
      "41\n",
      "49\n",
      "76\n",
      "19\n",
      "44\n",
      "49\n",
      "57\n",
      "85\n",
      "63\n",
      "91\n",
      "63\n",
      "94\n",
      "55\n",
      "59\n",
      "21\n",
      "59\n",
      "47\n",
      "31\n",
      "60\n",
      "44\n",
      "25\n",
      "11\n",
      "97\n",
      "96\n",
      "3\n",
      "46\n",
      "85\n",
      "56\n",
      "34\n",
      "41\n",
      "87\n",
      "38\n",
      "83\n",
      "45\n",
      "77\n",
      "15\n",
      "47\n",
      "68\n",
      "46\n",
      "87\n",
      "61\n",
      "69\n",
      "49\n",
      "86\n",
      "89\n",
      "36\n",
      "59\n",
      "54\n",
      "72\n",
      "62\n",
      "60\n",
      "97\n",
      "40\n",
      "69\n",
      "4\n",
      "94\n",
      "65\n",
      "39\n",
      "87\n",
      "48\n",
      "93\n",
      "38\n",
      "67\n",
      "26\n",
      "1\n",
      "10\n",
      "41\n",
      "47\n",
      "78\n",
      "87\n",
      "13\n",
      "11\n",
      "57\n",
      "45\n",
      "39\n",
      "8\n",
      "55\n",
      "21\n",
      "65\n",
      "97\n",
      "90\n",
      "98\n",
      "63\n",
      "78\n",
      "44\n",
      "44\n",
      "15\n",
      "53\n",
      "97\n",
      "13\n",
      "75\n",
      "73\n",
      "84\n",
      "84\n",
      "48\n",
      "12\n",
      "25\n",
      "7\n",
      "90\n",
      "7\n",
      "55\n",
      "90\n",
      "86\n",
      "67\n",
      "54\n",
      "77\n",
      "60\n",
      "9\n",
      "54\n",
      "34\n",
      "68\n",
      "25\n",
      "71\n",
      "20\n",
      "89\n",
      "24\n",
      "84\n",
      "4\n",
      "59\n",
      "26\n",
      "18\n",
      "37\n",
      "98\n",
      "64\n",
      "74\n",
      "94\n",
      "5\n",
      "43\n",
      "97\n",
      "93\n",
      "15\n",
      "17\n",
      "1\n",
      "58\n",
      "31\n",
      "8\n",
      "45\n",
      "28\n",
      "88\n",
      "87\n",
      "26\n",
      "33\n",
      "63\n",
      "16\n",
      "13\n",
      "76\n",
      "76\n",
      "38\n",
      "10\n",
      "70\n",
      "17\n",
      "78\n",
      "56\n",
      "75\n",
      "57\n",
      "79\n",
      "90\n",
      "38\n",
      "51\n",
      "27\n",
      "71\n",
      "96\n",
      "6\n",
      "40\n",
      "51\n",
      "47\n",
      "37\n",
      "41\n",
      "66\n",
      "41\n",
      "82\n",
      "14\n",
      "23\n",
      "6\n",
      "98\n",
      "11\n",
      "65\n",
      "64\n",
      "40\n",
      "15\n",
      "1\n",
      "29\n",
      "38\n",
      "75\n",
      "40\n",
      "31\n",
      "60\n",
      "79\n",
      "63\n",
      "36\n",
      "31\n",
      "21\n",
      "52\n",
      "71\n",
      "1\n",
      "61\n",
      "34\n",
      "34\n",
      "77\n",
      "35\n",
      "37\n",
      "7\n",
      "70\n",
      "20\n",
      "93\n",
      "41\n",
      "92\n",
      "87\n",
      "46\n",
      "30\n",
      "30\n",
      "46\n",
      "85\n",
      "32\n",
      "14\n",
      "51\n",
      "24\n",
      "5\n",
      "49\n",
      "61\n",
      "89\n",
      "48\n",
      "98\n",
      "94\n",
      "37\n",
      "94\n",
      "94\n",
      "52\n",
      "11\n",
      "61\n",
      "41\n",
      "50\n",
      "84\n",
      "76\n",
      "18\n",
      "64\n",
      "80\n",
      "62\n",
      "11\n",
      "41\n",
      "69\n",
      "34\n",
      "2\n",
      "45\n",
      "62\n",
      "87\n",
      "99\n",
      "45\n",
      "2\n",
      "27\n",
      "91\n",
      "19\n",
      "56\n",
      "20\n",
      "92\n",
      "54\n",
      "75\n",
      "83\n",
      "27\n",
      "49\n",
      "14\n",
      "2\n",
      "43\n",
      "96\n",
      "66\n",
      "81\n",
      "9\n",
      "44\n",
      "99\n",
      "87\n",
      "79\n",
      "11\n",
      "18\n",
      "62\n",
      "96\n",
      "94\n",
      "49\n",
      "47\n",
      "72\n",
      "26\n",
      "71\n",
      "76\n",
      "21\n",
      "81\n",
      "30\n",
      "99\n",
      "64\n",
      "0\n",
      "74\n",
      "82\n",
      "13\n",
      "69\n",
      "8\n",
      "3\n",
      "74\n",
      "89\n",
      "11\n",
      "16\n",
      "92\n",
      "79\n",
      "86\n",
      "72\n",
      "95\n",
      "38\n",
      "65\n",
      "61\n",
      "68\n",
      "17\n",
      "41\n",
      "49\n",
      "20\n",
      "4\n",
      "75\n",
      "48\n",
      "13\n",
      "60\n",
      "67\n",
      "62\n",
      "17\n",
      "37\n",
      "32\n",
      "59\n",
      "59\n",
      "38\n",
      "70\n",
      "79\n",
      "11\n",
      "49\n",
      "44\n",
      "0\n",
      "26\n",
      "45\n",
      "48\n",
      "1\n",
      "57\n",
      "10\n",
      "37\n",
      "97\n",
      "44\n",
      "43\n",
      "63\n",
      "55\n",
      "37\n",
      "20\n",
      "49\n",
      "19\n",
      "16\n",
      "26\n",
      "21\n",
      "79\n",
      "40\n",
      "68\n",
      "74\n",
      "95\n",
      "46\n",
      "94\n",
      "68\n",
      "13\n",
      "22\n",
      "83\n",
      "46\n",
      "74\n",
      "35\n",
      "60\n",
      "11\n",
      "21\n",
      "34\n",
      "39\n",
      "65\n",
      "13\n",
      "20\n",
      "21\n",
      "99\n",
      "68\n",
      "88\n",
      "93\n",
      "49\n",
      "69\n",
      "17\n",
      "55\n",
      "81\n",
      "63\n",
      "14\n",
      "73\n",
      "17\n",
      "13\n",
      "99\n",
      "61\n",
      "24\n",
      "22\n",
      "23\n",
      "94\n",
      "90\n",
      "8\n",
      "68\n",
      "52\n",
      "20\n",
      "64\n",
      "54\n",
      "53\n",
      "3\n",
      "88\n",
      "53\n",
      "27\n",
      "5\n",
      "47\n",
      "97\n",
      "5\n",
      "35\n",
      "71\n",
      "54\n",
      "54\n",
      "17\n",
      "56\n",
      "54\n",
      "15\n",
      "69\n",
      "65\n",
      "24\n",
      "8\n",
      "72\n",
      "77\n",
      "75\n",
      "66\n",
      "93\n",
      "94\n",
      "27\n",
      "98\n",
      "75\n",
      "44\n",
      "37\n",
      "8\n",
      "10\n",
      "84\n",
      "72\n",
      "34\n",
      "37\n",
      "2\n",
      "86\n",
      "20\n",
      "90\n",
      "49\n",
      "95\n",
      "29\n",
      "34\n",
      "46\n",
      "43\n",
      "72\n",
      "18\n",
      "51\n",
      "87\n",
      "18\n",
      "41\n",
      "93\n",
      "72\n",
      "95\n",
      "34\n",
      "42\n",
      "79\n",
      "79\n",
      "17\n",
      "73\n",
      "97\n",
      "45\n",
      "97\n",
      "29\n",
      "86\n",
      "29\n",
      "0\n",
      "19\n",
      "12\n",
      "75\n",
      "97\n",
      "13\n",
      "61\n",
      "74\n",
      "85\n",
      "29\n",
      "50\n",
      "43\n",
      "3\n",
      "25\n",
      "13\n",
      "50\n",
      "60\n",
      "30\n",
      "61\n",
      "34\n",
      "84\n",
      "1\n",
      "58\n",
      "35\n",
      "4\n",
      "77\n",
      "22\n",
      "87\n",
      "38\n",
      "11\n",
      "32\n",
      "12\n",
      "50\n",
      "8\n",
      "96\n",
      "61\n",
      "43\n",
      "58\n",
      "92\n",
      "32\n",
      "32\n",
      "25\n",
      "0\n",
      "34\n",
      "75\n",
      "68\n",
      "27\n",
      "15\n",
      "0\n",
      "38\n",
      "10\n",
      "3\n",
      "44\n",
      "30\n",
      "43\n",
      "59\n",
      "50\n",
      "40\n",
      "67\n",
      "76\n",
      "49\n",
      "98\n",
      "57\n",
      "16\n",
      "56\n",
      "84\n",
      "75\n",
      "90\n",
      "10\n",
      "83\n",
      "22\n",
      "59\n",
      "93\n",
      "36\n",
      "51\n",
      "6\n",
      "74\n",
      "1\n",
      "97\n",
      "12\n",
      "79\n",
      "49\n",
      "94\n",
      "39\n",
      "25\n",
      "98\n",
      "10\n",
      "58\n",
      "79\n",
      "54\n",
      "64\n",
      "1\n",
      "24\n",
      "46\n",
      "51\n",
      "45\n",
      "70\n",
      "29\n",
      "96\n",
      "2\n",
      "7\n",
      "95\n",
      "27\n",
      "83\n",
      "89\n",
      "52\n",
      "24\n",
      "49\n",
      "5\n",
      "80\n",
      "53\n",
      "75\n",
      "55\n",
      "14\n",
      "15\n",
      "69\n",
      "51\n",
      "24\n",
      "2\n",
      "68\n",
      "24\n",
      "75\n",
      "75\n",
      "41\n",
      "13\n",
      "44\n",
      "41\n",
      "31\n",
      "74\n",
      "18\n",
      "43\n",
      "0\n",
      "13\n",
      "15\n",
      "7\n",
      "17\n",
      "83\n",
      "79\n",
      "34\n",
      "74\n",
      "86\n",
      "20\n",
      "50\n",
      "72\n",
      "14\n",
      "86\n",
      "88\n",
      "98\n",
      "77\n",
      "1\n",
      "79\n",
      "12\n",
      "87\n",
      "78\n",
      "65\n",
      "1\n",
      "59\n",
      "48\n",
      "83\n",
      "58\n",
      "13\n",
      "56\n",
      "94\n",
      "50\n",
      "13\n",
      "55\n",
      "97\n",
      "10\n",
      "21\n",
      "19\n",
      "22\n",
      "54\n",
      "75\n",
      "75\n",
      "27\n",
      "5\n",
      "75\n",
      "6\n",
      "75\n",
      "35\n",
      "19\n",
      "79\n",
      "48\n",
      "18\n",
      "12\n",
      "32\n",
      "3\n",
      "60\n",
      "65\n",
      "85\n",
      "77\n",
      "43\n",
      "65\n",
      "85\n",
      "96\n",
      "98\n",
      "66\n",
      "62\n",
      "73\n",
      "83\n",
      "65\n",
      "58\n",
      "12\n",
      "38\n",
      "27\n",
      "81\n",
      "21\n",
      "29\n",
      "51\n",
      "58\n",
      "88\n",
      "89\n",
      "5\n",
      "15\n",
      "10\n",
      "37\n",
      "95\n",
      "50\n",
      "30\n",
      "74\n",
      "98\n",
      "40\n",
      "50\n",
      "52\n",
      "14\n",
      "63\n",
      "72\n",
      "53\n",
      "91\n",
      "81\n",
      "73\n",
      "16\n",
      "32\n",
      "90\n",
      "52\n",
      "41\n",
      "11\n",
      "38\n",
      "14\n",
      "43\n",
      "80\n",
      "65\n",
      "46\n",
      "92\n",
      "52\n",
      "75\n",
      "78\n",
      "60\n",
      "70\n",
      "36\n",
      "19\n",
      "2\n",
      "8\n",
      "61\n",
      "55\n",
      "24\n",
      "47\n",
      "30\n",
      "70\n",
      "25\n",
      "7\n",
      "67\n",
      "53\n",
      "11\n",
      "54\n",
      "74\n",
      "66\n",
      "41\n",
      "47\n",
      "52\n",
      "59\n",
      "68\n",
      "21\n",
      "13\n",
      "62\n",
      "58\n",
      "92\n",
      "18\n",
      "24\n",
      "30\n",
      "78\n",
      "14\n",
      "86\n",
      "78\n",
      "76\n",
      "68\n",
      "56\n",
      "70\n",
      "31\n",
      "97\n",
      "72\n",
      "7\n",
      "84\n",
      "43\n",
      "61\n",
      "33\n",
      "42\n",
      "89\n",
      "42\n",
      "38\n",
      "92\n",
      "24\n",
      "49\n",
      "52\n",
      "66\n",
      "99\n",
      "96\n",
      "34\n",
      "14\n",
      "11\n",
      "92\n",
      "29\n",
      "3\n",
      "55\n",
      "61\n",
      "90\n",
      "94\n",
      "29\n",
      "90\n",
      "43\n",
      "21\n",
      "66\n",
      "57\n",
      "25\n",
      "37\n",
      "0\n",
      "1\n",
      "56\n",
      "30\n",
      "80\n",
      "93\n",
      "8\n",
      "23\n",
      "98\n",
      "64\n",
      "69\n",
      "68\n",
      "72\n",
      "1\n",
      "35\n",
      "92\n",
      "22\n",
      "52\n",
      "90\n",
      "91\n",
      "37\n",
      "71\n",
      "27\n",
      "89\n",
      "28\n",
      "0\n",
      "79\n",
      "20\n",
      "18\n",
      "39\n",
      "79\n",
      "45\n",
      "96\n",
      "68\n",
      "24\n",
      "0\n",
      "42\n",
      "81\n",
      "81\n",
      "87\n",
      "33\n",
      "9\n",
      "46\n",
      "59\n",
      "64\n",
      "70\n",
      "25\n",
      "46\n",
      "89\n",
      "93\n",
      "58\n",
      "37\n",
      "3\n",
      "57\n",
      "75\n",
      "5\n",
      "80\n",
      "70\n",
      "64\n",
      "34\n",
      "22\n",
      "54\n",
      "34\n",
      "32\n",
      "9\n",
      "31\n",
      "77\n",
      "43\n",
      "33\n",
      "79\n",
      "63\n",
      "63\n",
      "1\n",
      "99\n",
      "27\n",
      "12\n",
      "74\n",
      "93\n",
      "20\n",
      "60\n",
      "66\n",
      "40\n",
      "59\n",
      "46\n",
      "47\n",
      "52\n",
      "89\n",
      "93\n",
      "94\n",
      "54\n",
      "15\n",
      "96\n",
      "79\n",
      "49\n",
      "13\n",
      "41\n",
      "14\n",
      "30\n",
      "76\n",
      "21\n",
      "82\n",
      "52\n",
      "79\n",
      "4\n",
      "46\n",
      "14\n",
      "43\n",
      "32\n",
      "34\n",
      "83\n",
      "13\n",
      "19\n",
      "31\n",
      "0\n",
      "95\n",
      "32\n",
      "71\n",
      "8\n",
      "64\n",
      "53\n",
      "47\n",
      "22\n",
      "30\n",
      "22\n",
      "7\n",
      "84\n",
      "92\n",
      "30\n",
      "23\n",
      "63\n",
      "22\n",
      "57\n",
      "24\n",
      "23\n",
      "32\n",
      "72\n",
      "64\n",
      "43\n",
      "13\n",
      "98\n",
      "26\n",
      "55\n",
      "83\n",
      "12\n",
      "76\n",
      "47\n",
      "24\n",
      "92\n",
      "40\n",
      "86\n",
      "39\n",
      "37\n",
      "71\n",
      "39\n",
      "72\n",
      "87\n",
      "17\n",
      "13\n",
      "39\n",
      "35\n",
      "54\n",
      "88\n",
      "1\n",
      "61\n",
      "24\n",
      "69\n",
      "4\n",
      "9\n",
      "98\n",
      "74\n",
      "58\n",
      "76\n",
      "96\n",
      "4\n",
      "84\n",
      "30\n",
      "88\n",
      "79\n",
      "5\n",
      "10\n",
      "33\n",
      "54\n",
      "36\n",
      "46\n",
      "6\n",
      "46\n",
      "86\n",
      "39\n",
      "83\n",
      "77\n",
      "69\n",
      "65\n",
      "14\n",
      "33\n",
      "61\n",
      "35\n",
      "20\n",
      "9\n",
      "37\n",
      "63\n",
      "82\n",
      "46\n",
      "72\n",
      "77\n",
      "16\n",
      "64\n",
      "46\n",
      "22\n",
      "75\n",
      "78\n",
      "46\n",
      "10\n",
      "85\n",
      "7\n",
      "68\n",
      "28\n",
      "58\n",
      "55\n",
      "19\n",
      "44\n",
      "98\n",
      "27\n",
      "34\n",
      "17\n",
      "25\n",
      "58\n",
      "29\n",
      "85\n",
      "85\n",
      "25\n",
      "35\n",
      "12\n",
      "8\n",
      "34\n",
      "16\n",
      "86\n",
      "48\n",
      "49\n",
      "15\n",
      "55\n",
      "53\n",
      "99\n",
      "66\n",
      "26\n",
      "88\n",
      "64\n",
      "87\n",
      "41\n",
      "17\n",
      "40\n",
      "6\n",
      "55\n",
      "8\n",
      "95\n",
      "94\n",
      "2\n",
      "66\n",
      "4\n",
      "68\n",
      "11\n",
      "20\n",
      "49\n",
      "23\n",
      "72\n",
      "16\n",
      "0\n",
      "86\n",
      "59\n",
      "93\n",
      "48\n",
      "40\n",
      "33\n",
      "17\n",
      "52\n",
      "54\n",
      "94\n",
      "87\n",
      "77\n",
      "79\n",
      "5\n",
      "91\n",
      "30\n",
      "25\n",
      "75\n",
      "31\n",
      "14\n",
      "94\n",
      "57\n",
      "63\n",
      "81\n",
      "4\n",
      "99\n",
      "45\n",
      "32\n",
      "11\n",
      "9\n",
      "59\n",
      "81\n",
      "40\n",
      "48\n",
      "6\n",
      "98\n",
      "70\n",
      "93\n",
      "0\n",
      "14\n",
      "49\n",
      "51\n",
      "4\n",
      "14\n",
      "42\n",
      "68\n",
      "78\n",
      "47\n",
      "62\n",
      "62\n",
      "90\n",
      "8\n",
      "51\n",
      "91\n",
      "80\n",
      "79\n",
      "22\n",
      "18\n",
      "61\n",
      "62\n",
      "54\n",
      "34\n",
      "42\n",
      "33\n",
      "16\n",
      "99\n",
      "99\n",
      "27\n",
      "13\n",
      "39\n",
      "56\n",
      "53\n",
      "82\n",
      "48\n",
      "76\n",
      "82\n",
      "49\n",
      "40\n",
      "58\n",
      "58\n",
      "37\n",
      "38\n",
      "93\n",
      "68\n",
      "13\n",
      "35\n",
      "68\n",
      "47\n",
      "13\n",
      "91\n",
      "53\n",
      "23\n",
      "29\n",
      "89\n",
      "35\n",
      "43\n",
      "62\n",
      "15\n",
      "97\n",
      "15\n",
      "44\n",
      "75\n",
      "84\n",
      "41\n",
      "71\n",
      "78\n",
      "17\n",
      "76\n",
      "78\n",
      "88\n",
      "49\n",
      "35\n",
      "54\n",
      "86\n",
      "12\n",
      "74\n",
      "80\n",
      "33\n",
      "49\n",
      "5\n",
      "63\n",
      "78\n",
      "41\n",
      "36\n",
      "37\n",
      "66\n",
      "98\n",
      "76\n",
      "8\n",
      "13\n",
      "53\n",
      "87\n",
      "19\n",
      "38\n",
      "18\n",
      "32\n",
      "88\n",
      "78\n",
      "99\n",
      "75\n",
      "21\n",
      "74\n",
      "97\n",
      "75\n",
      "64\n",
      "52\n",
      "94\n",
      "10\n",
      "34\n",
      "14\n",
      "21\n",
      "61\n",
      "1\n",
      "21\n",
      "81\n",
      "98\n",
      "69\n",
      "52\n",
      "63\n",
      "20\n",
      "91\n",
      "68\n",
      "64\n",
      "76\n",
      "5\n",
      "9\n",
      "43\n",
      "49\n",
      "55\n",
      "55\n",
      "32\n",
      "83\n",
      "42\n",
      "58\n",
      "44\n",
      "48\n",
      "15\n",
      "48\n",
      "17\n",
      "35\n",
      "11\n",
      "15\n",
      "21\n",
      "81\n",
      "59\n",
      "14\n",
      "37\n",
      "75\n",
      "2\n",
      "10\n",
      "19\n",
      "58\n",
      "90\n",
      "43\n",
      "3\n",
      "71\n",
      "28\n",
      "68\n",
      "80\n",
      "61\n",
      "87\n",
      "25\n",
      "89\n",
      "42\n",
      "74\n",
      "91\n",
      "47\n",
      "5\n",
      "22\n",
      "6\n",
      "58\n",
      "61\n",
      "91\n",
      "71\n",
      "74\n",
      "82\n",
      "66\n",
      "30\n",
      "47\n",
      "38\n",
      "45\n",
      "54\n",
      "48\n",
      "13\n",
      "85\n",
      "28\n",
      "21\n",
      "44\n",
      "27\n",
      "0\n",
      "8\n",
      "27\n",
      "98\n",
      "48\n",
      "81\n",
      "36\n",
      "29\n",
      "86\n",
      "19\n",
      "82\n",
      "89\n",
      "35\n",
      "13\n",
      "42\n",
      "60\n",
      "69\n",
      "12\n",
      "89\n",
      "24\n",
      "49\n",
      "12\n",
      "71\n",
      "25\n",
      "71\n",
      "46\n",
      "14\n",
      "88\n",
      "64\n",
      "13\n",
      "25\n",
      "11\n",
      "44\n",
      "17\n",
      "18\n",
      "74\n",
      "75\n",
      "14\n",
      "83\n",
      "60\n",
      "30\n",
      "57\n",
      "94\n",
      "48\n",
      "75\n",
      "15\n",
      "51\n",
      "93\n",
      "93\n",
      "41\n",
      "52\n",
      "52\n",
      "12\n",
      "64\n",
      "87\n",
      "99\n",
      "86\n",
      "5\n",
      "42\n",
      "71\n",
      "64\n",
      "99\n",
      "49\n",
      "22\n",
      "52\n",
      "5\n",
      "60\n",
      "71\n",
      "72\n",
      "74\n",
      "24\n",
      "30\n",
      "76\n",
      "15\n",
      "39\n",
      "16\n",
      "21\n",
      "15\n",
      "38\n",
      "30\n",
      "55\n",
      "98\n",
      "25\n",
      "40\n",
      "82\n",
      "47\n",
      "71\n",
      "52\n",
      "47\n",
      "60\n",
      "55\n",
      "16\n",
      "61\n",
      "36\n",
      "90\n",
      "32\n",
      "21\n",
      "30\n",
      "78\n",
      "43\n",
      "81\n",
      "88\n",
      "49\n",
      "96\n",
      "10\n",
      "95\n",
      "15\n",
      "85\n",
      "89\n",
      "79\n",
      "26\n",
      "18\n",
      "97\n",
      "14\n",
      "15\n",
      "16\n",
      "75\n",
      "88\n",
      "64\n",
      "54\n",
      "71\n",
      "6\n",
      "96\n",
      "8\n",
      "67\n",
      "0\n",
      "78\n",
      "57\n",
      "66\n",
      "48\n",
      "67\n",
      "60\n",
      "89\n",
      "16\n",
      "58\n",
      "61\n",
      "22\n",
      "75\n",
      "37\n",
      "3\n",
      "60\n",
      "9\n",
      "27\n",
      "83\n",
      "89\n",
      "42\n",
      "88\n",
      "44\n",
      "2\n",
      "62\n",
      "94\n",
      "32\n",
      "66\n",
      "8\n",
      "40\n",
      "44\n",
      "45\n",
      "26\n",
      "48\n",
      "87\n",
      "59\n",
      "35\n",
      "61\n",
      "64\n",
      "43\n",
      "25\n",
      "48\n",
      "45\n",
      "36\n",
      "29\n",
      "51\n",
      "76\n",
      "74\n",
      "61\n",
      "56\n",
      "55\n",
      "44\n",
      "50\n",
      "8\n",
      "27\n",
      "22\n",
      "61\n",
      "77\n",
      "85\n",
      "95\n",
      "78\n",
      "0\n",
      "80\n",
      "26\n",
      "33\n",
      "49\n",
      "51\n",
      "36\n",
      "98\n",
      "39\n",
      "76\n",
      "95\n",
      "31\n",
      "45\n",
      "27\n",
      "60\n",
      "3\n",
      "51\n",
      "94\n",
      "67\n",
      "62\n",
      "98\n",
      "26\n",
      "61\n",
      "29\n",
      "64\n",
      "4\n",
      "17\n",
      "99\n",
      "30\n",
      "86\n",
      "83\n",
      "78\n",
      "25\n",
      "50\n",
      "97\n",
      "52\n",
      "28\n",
      "44\n",
      "28\n",
      "22\n",
      "5\n",
      "35\n",
      "37\n",
      "66\n",
      "88\n",
      "1\n",
      "57\n",
      "12\n",
      "44\n",
      "97\n",
      "78\n",
      "7\n",
      "94\n",
      "85\n",
      "48\n",
      "16\n",
      "85\n",
      "63\n",
      "59\n",
      "70\n",
      "62\n",
      "58\n",
      "54\n",
      "60\n",
      "44\n",
      "23\n",
      "71\n",
      "10\n",
      "89\n",
      "31\n",
      "70\n",
      "73\n",
      "43\n",
      "43\n",
      "86\n",
      "15\n",
      "24\n",
      "84\n",
      "42\n",
      "60\n",
      "48\n",
      "93\n",
      "16\n",
      "30\n",
      "13\n",
      "21\n",
      "78\n",
      "68\n",
      "48\n",
      "74\n",
      "42\n",
      "20\n",
      "14\n",
      "78\n",
      "62\n",
      "76\n",
      "42\n",
      "28\n",
      "74\n",
      "78\n",
      "27\n",
      "51\n",
      "83\n",
      "48\n",
      "79\n",
      "67\n",
      "43\n",
      "90\n",
      "18\n",
      "40\n",
      "88\n",
      "15\n",
      "89\n",
      "0\n",
      "80\n",
      "95\n",
      "59\n",
      "67\n",
      "57\n",
      "64\n",
      "55\n",
      "72\n",
      "39\n",
      "1\n",
      "14\n",
      "10\n",
      "40\n",
      "66\n",
      "32\n",
      "11\n",
      "54\n",
      "14\n",
      "15\n",
      "84\n",
      "7\n",
      "15\n",
      "70\n",
      "45\n",
      "28\n",
      "27\n",
      "36\n",
      "31\n",
      "16\n",
      "59\n",
      "6\n",
      "19\n",
      "87\n",
      "15\n",
      "81\n",
      "25\n",
      "98\n",
      "2\n",
      "68\n",
      "47\n",
      "18\n",
      "66\n",
      "66\n",
      "17\n",
      "65\n",
      "90\n",
      "98\n",
      "45\n",
      "76\n",
      "95\n",
      "5\n",
      "89\n",
      "69\n",
      "57\n",
      "60\n",
      "16\n",
      "52\n",
      "6\n",
      "67\n",
      "60\n",
      "67\n",
      "52\n",
      "2\n",
      "94\n",
      "25\n",
      "58\n",
      "65\n",
      "38\n",
      "85\n",
      "48\n",
      "82\n",
      "21\n",
      "55\n",
      "69\n",
      "39\n",
      "12\n",
      "29\n",
      "5\n",
      "17\n",
      "87\n",
      "78\n",
      "70\n",
      "30\n",
      "87\n",
      "94\n",
      "75\n",
      "44\n",
      "73\n",
      "67\n",
      "62\n",
      "41\n",
      "1\n",
      "16\n",
      "85\n",
      "29\n",
      "44\n",
      "69\n",
      "26\n",
      "46\n",
      "20\n",
      "7\n",
      "93\n",
      "63\n",
      "53\n",
      "40\n",
      "37\n",
      "33\n",
      "76\n",
      "48\n",
      "63\n",
      "84\n",
      "31\n",
      "54\n",
      "28\n",
      "72\n",
      "34\n",
      "47\n",
      "63\n",
      "54\n",
      "35\n",
      "93\n",
      "61\n",
      "2\n",
      "51\n",
      "7\n",
      "68\n",
      "81\n",
      "81\n",
      "39\n",
      "13\n",
      "37\n",
      "35\n",
      "81\n",
      "51\n",
      "18\n",
      "4\n",
      "23\n",
      "93\n",
      "94\n",
      "77\n",
      "47\n",
      "51\n",
      "5\n",
      "90\n",
      "86\n",
      "48\n",
      "96\n",
      "23\n",
      "79\n",
      "13\n",
      "98\n",
      "71\n",
      "60\n",
      "62\n",
      "39\n",
      "68\n",
      "52\n",
      "14\n",
      "21\n",
      "15\n",
      "77\n",
      "94\n",
      "73\n",
      "70\n",
      "55\n",
      "76\n",
      "72\n",
      "3\n",
      "18\n",
      "0\n",
      "99\n",
      "24\n",
      "56\n",
      "0\n",
      "82\n",
      "72\n",
      "37\n",
      "20\n",
      "54\n",
      "11\n",
      "86\n",
      "65\n",
      "78\n",
      "22\n",
      "48\n",
      "1\n",
      "33\n",
      "77\n",
      "49\n",
      "89\n",
      "36\n",
      "42\n",
      "20\n",
      "2\n",
      "32\n",
      "87\n",
      "71\n",
      "36\n",
      "27\n",
      "36\n",
      "54\n",
      "92\n",
      "88\n",
      "6\n",
      "31\n",
      "54\n",
      "32\n",
      "58\n",
      "10\n",
      "64\n",
      "93\n",
      "3\n",
      "55\n",
      "49\n",
      "33\n",
      "99\n",
      "62\n",
      "34\n",
      "53\n",
      "17\n",
      "93\n",
      "66\n",
      "0\n",
      "58\n",
      "4\n",
      "37\n",
      "1\n",
      "58\n",
      "66\n",
      "58\n",
      "88\n",
      "39\n",
      "40\n",
      "68\n",
      "4\n",
      "55\n",
      "65\n",
      "72\n",
      "13\n",
      "17\n",
      "30\n",
      "1\n",
      "59\n",
      "73\n",
      "58\n",
      "90\n",
      "56\n",
      "44\n",
      "16\n",
      "32\n",
      "15\n",
      "90\n",
      "99\n",
      "40\n",
      "63\n",
      "22\n",
      "2\n",
      "14\n",
      "72\n",
      "76\n",
      "73\n",
      "2\n",
      "79\n",
      "5\n",
      "39\n",
      "12\n",
      "43\n",
      "91\n",
      "97\n",
      "65\n",
      "62\n",
      "86\n",
      "66\n",
      "24\n",
      "62\n",
      "49\n",
      "30\n",
      "24\n",
      "73\n",
      "31\n",
      "55\n",
      "46\n",
      "11\n",
      "20\n",
      "83\n",
      "80\n",
      "38\n",
      "30\n",
      "93\n",
      "65\n",
      "41\n",
      "0\n",
      "35\n",
      "54\n",
      "16\n",
      "87\n",
      "81\n",
      "12\n",
      "49\n",
      "60\n",
      "81\n",
      "89\n",
      "42\n",
      "51\n",
      "36\n",
      "59\n",
      "92\n",
      "7\n",
      "94\n",
      "80\n",
      "56\n",
      "37\n",
      "63\n",
      "74\n",
      "46\n",
      "34\n",
      "88\n",
      "85\n",
      "24\n",
      "51\n",
      "41\n",
      "62\n",
      "6\n",
      "38\n",
      "26\n",
      "22\n",
      "52\n",
      "32\n",
      "70\n",
      "96\n",
      "44\n",
      "57\n",
      "13\n",
      "47\n",
      "8\n",
      "73\n",
      "17\n",
      "14\n",
      "18\n",
      "91\n",
      "19\n",
      "57\n",
      "71\n",
      "16\n",
      "54\n",
      "52\n",
      "26\n",
      "50\n",
      "81\n",
      "74\n",
      "74\n",
      "71\n",
      "85\n",
      "8\n",
      "31\n",
      "28\n",
      "17\n",
      "26\n",
      "10\n",
      "93\n",
      "16\n",
      "0\n",
      "37\n",
      "26\n",
      "71\n",
      "34\n",
      "50\n",
      "99\n",
      "44\n",
      "58\n",
      "16\n",
      "8\n",
      "34\n",
      "35\n",
      "86\n",
      "41\n",
      "0\n",
      "44\n",
      "46\n",
      "6\n",
      "42\n",
      "62\n",
      "73\n",
      "31\n",
      "73\n",
      "62\n",
      "97\n",
      "97\n",
      "0\n",
      "57\n",
      "19\n",
      "46\n",
      "53\n",
      "69\n",
      "47\n",
      "13\n",
      "84\n",
      "67\n",
      "43\n",
      "80\n",
      "59\n",
      "20\n",
      "76\n",
      "65\n",
      "79\n",
      "99\n",
      "62\n",
      "58\n",
      "55\n",
      "26\n",
      "1\n",
      "46\n",
      "90\n",
      "66\n",
      "69\n",
      "39\n",
      "71\n",
      "88\n",
      "6\n",
      "51\n",
      "34\n",
      "80\n",
      "67\n",
      "78\n",
      "84\n",
      "23\n",
      "68\n",
      "74\n",
      "78\n",
      "78\n",
      "86\n",
      "1\n",
      "61\n",
      "2\n",
      "72\n",
      "32\n",
      "64\n",
      "43\n",
      "60\n",
      "27\n",
      "62\n",
      "81\n",
      "64\n",
      "35\n",
      "32\n",
      "91\n",
      "85\n",
      "70\n",
      "28\n",
      "59\n",
      "22\n",
      "43\n",
      "35\n",
      "74\n",
      "84\n",
      "72\n",
      "81\n",
      "16\n",
      "25\n",
      "12\n",
      "24\n",
      "61\n",
      "9\n",
      "8\n",
      "20\n",
      "11\n",
      "49\n",
      "0\n",
      "55\n",
      "31\n",
      "18\n",
      "35\n",
      "47\n",
      "47\n",
      "30\n",
      "88\n",
      "32\n",
      "40\n",
      "97\n",
      "17\n",
      "81\n",
      "76\n",
      "62\n",
      "39\n",
      "72\n",
      "95\n",
      "30\n",
      "86\n",
      "98\n",
      "48\n",
      "11\n",
      "88\n",
      "88\n",
      "21\n",
      "36\n",
      "55\n",
      "82\n",
      "40\n",
      "47\n",
      "10\n",
      "61\n",
      "93\n",
      "15\n",
      "54\n",
      "88\n",
      "33\n",
      "35\n",
      "39\n",
      "70\n",
      "15\n",
      "36\n",
      "94\n",
      "70\n",
      "96\n",
      "70\n",
      "92\n",
      "16\n",
      "3\n",
      "86\n",
      "71\n",
      "42\n",
      "99\n",
      "16\n",
      "46\n",
      "28\n",
      "98\n",
      "42\n",
      "17\n",
      "89\n",
      "14\n",
      "57\n",
      "81\n",
      "74\n",
      "10\n",
      "81\n",
      "40\n",
      "49\n",
      "29\n",
      "87\n",
      "58\n",
      "36\n",
      "65\n",
      "83\n",
      "10\n",
      "34\n",
      "12\n",
      "5\n",
      "17\n",
      "29\n",
      "80\n",
      "6\n",
      "65\n",
      "9\n",
      "55\n",
      "38\n",
      "88\n",
      "43\n",
      "57\n",
      "50\n",
      "99\n",
      "20\n",
      "0\n",
      "32\n",
      "90\n",
      "70\n",
      "14\n",
      "88\n",
      "56\n",
      "71\n",
      "11\n",
      "4\n",
      "39\n",
      "66\n",
      "96\n",
      "63\n",
      "13\n",
      "39\n",
      "27\n",
      "31\n",
      "84\n",
      "7\n",
      "37\n",
      "18\n",
      "43\n",
      "96\n",
      "2\n",
      "6\n",
      "59\n",
      "78\n",
      "19\n",
      "39\n",
      "97\n",
      "6\n",
      "39\n",
      "77\n",
      "74\n",
      "52\n",
      "5\n",
      "61\n",
      "21\n",
      "20\n",
      "50\n",
      "65\n",
      "48\n",
      "39\n",
      "14\n",
      "74\n",
      "36\n",
      "12\n",
      "93\n",
      "43\n",
      "51\n",
      "79\n",
      "78\n",
      "6\n",
      "4\n",
      "36\n",
      "32\n",
      "25\n",
      "97\n",
      "94\n",
      "34\n",
      "34\n",
      "59\n",
      "22\n",
      "16\n",
      "70\n",
      "9\n",
      "25\n",
      "77\n",
      "74\n",
      "17\n",
      "28\n",
      "47\n",
      "43\n",
      "13\n",
      "50\n",
      "97\n",
      "49\n",
      "78\n",
      "68\n",
      "99\n",
      "52\n",
      "28\n",
      "43\n",
      "23\n",
      "23\n",
      "55\n",
      "74\n",
      "87\n",
      "50\n",
      "5\n",
      "51\n",
      "63\n",
      "2\n",
      "57\n",
      "99\n",
      "53\n",
      "85\n",
      "74\n",
      "72\n",
      "75\n",
      "94\n",
      "95\n",
      "40\n",
      "49\n",
      "64\n",
      "8\n",
      "37\n",
      "0\n",
      "86\n",
      "9\n",
      "51\n",
      "40\n",
      "9\n",
      "39\n",
      "70\n",
      "96\n",
      "44\n",
      "62\n",
      "32\n",
      "61\n",
      "35\n",
      "8\n",
      "2\n",
      "66\n",
      "66\n",
      "46\n",
      "73\n",
      "20\n",
      "95\n",
      "68\n",
      "52\n",
      "94\n",
      "22\n",
      "9\n",
      "23\n",
      "11\n",
      "55\n",
      "44\n",
      "47\n",
      "20\n",
      "17\n",
      "11\n",
      "73\n",
      "96\n",
      "60\n",
      "28\n",
      "10\n",
      "0\n",
      "10\n",
      "31\n",
      "44\n",
      "29\n",
      "24\n",
      "23\n",
      "52\n",
      "60\n",
      "81\n",
      "57\n",
      "52\n",
      "87\n",
      "27\n",
      "22\n",
      "83\n",
      "22\n",
      "40\n",
      "56\n",
      "1\n",
      "45\n",
      "29\n",
      "60\n",
      "65\n",
      "88\n",
      "48\n",
      "8\n",
      "29\n",
      "18\n",
      "71\n",
      "80\n",
      "55\n",
      "80\n",
      "73\n",
      "27\n",
      "5\n",
      "69\n",
      "46\n",
      "64\n",
      "90\n",
      "52\n",
      "1\n",
      "39\n",
      "39\n",
      "86\n",
      "75\n",
      "2\n",
      "36\n",
      "13\n",
      "57\n",
      "30\n",
      "74\n",
      "85\n",
      "33\n",
      "6\n",
      "72\n",
      "54\n",
      "47\n",
      "71\n",
      "7\n",
      "98\n",
      "69\n",
      "56\n",
      "14\n",
      "50\n",
      "37\n",
      "40\n",
      "97\n",
      "72\n",
      "88\n",
      "10\n",
      "75\n",
      "83\n",
      "74\n",
      "66\n",
      "52\n",
      "52\n",
      "86\n",
      "66\n",
      "24\n",
      "69\n",
      "41\n",
      "13\n",
      "39\n",
      "5\n",
      "61\n",
      "48\n",
      "44\n",
      "23\n",
      "38\n",
      "44\n",
      "64\n",
      "30\n",
      "2\n",
      "54\n",
      "12\n",
      "21\n",
      "56\n",
      "72\n",
      "93\n",
      "46\n",
      "73\n",
      "47\n",
      "89\n",
      "24\n",
      "52\n",
      "75\n",
      "20\n",
      "92\n",
      "96\n",
      "5\n",
      "63\n",
      "39\n",
      "45\n",
      "67\n",
      "2\n",
      "79\n",
      "76\n",
      "27\n",
      "81\n",
      "89\n",
      "83\n",
      "60\n",
      "48\n",
      "2\n",
      "2\n",
      "30\n",
      "2\n",
      "21\n",
      "90\n",
      "94\n",
      "74\n",
      "71\n",
      "75\n",
      "79\n",
      "42\n",
      "75\n",
      "14\n",
      "89\n",
      "50\n",
      "83\n",
      "42\n",
      "67\n",
      "81\n",
      "73\n",
      "52\n",
      "17\n",
      "76\n",
      "5\n",
      "68\n",
      "13\n",
      "37\n",
      "94\n",
      "92\n",
      "0\n",
      "48\n",
      "15\n",
      "15\n",
      "39\n",
      "40\n",
      "94\n",
      "99\n",
      "68\n",
      "52\n",
      "19\n",
      "4\n",
      "54\n",
      "89\n",
      "40\n",
      "27\n",
      "97\n",
      "14\n",
      "93\n",
      "66\n",
      "74\n",
      "26\n",
      "36\n",
      "66\n",
      "44\n",
      "59\n",
      "33\n",
      "79\n",
      "63\n",
      "97\n",
      "43\n",
      "48\n",
      "78\n",
      "25\n",
      "32\n",
      "18\n",
      "40\n",
      "44\n",
      "80\n",
      "16\n",
      "45\n",
      "45\n",
      "12\n",
      "99\n",
      "18\n",
      "6\n",
      "41\n",
      "46\n",
      "69\n",
      "18\n",
      "44\n",
      "34\n",
      "32\n",
      "30\n",
      "9\n",
      "72\n",
      "85\n",
      "15\n",
      "92\n",
      "5\n",
      "71\n",
      "52\n",
      "56\n",
      "88\n",
      "22\n",
      "64\n",
      "31\n",
      "63\n",
      "14\n",
      "56\n",
      "99\n",
      "72\n",
      "22\n",
      "20\n",
      "67\n",
      "57\n",
      "93\n",
      "29\n",
      "72\n",
      "91\n",
      "64\n",
      "36\n",
      "22\n",
      "49\n",
      "26\n",
      "84\n",
      "47\n",
      "34\n",
      "85\n",
      "9\n",
      "22\n",
      "29\n",
      "39\n",
      "32\n",
      "94\n",
      "93\n",
      "25\n",
      "18\n",
      "53\n",
      "12\n",
      "27\n",
      "10\n",
      "99\n",
      "88\n",
      "16\n",
      "91\n",
      "78\n",
      "7\n",
      "72\n",
      "12\n",
      "97\n",
      "37\n",
      "86\n",
      "87\n",
      "57\n",
      "36\n",
      "35\n",
      "44\n",
      "57\n",
      "27\n",
      "3\n",
      "26\n",
      "96\n",
      "39\n",
      "43\n",
      "34\n",
      "89\n",
      "48\n",
      "56\n",
      "18\n",
      "45\n",
      "92\n",
      "97\n",
      "8\n",
      "18\n",
      "66\n",
      "81\n",
      "37\n",
      "51\n",
      "10\n",
      "77\n",
      "97\n",
      "33\n",
      "60\n",
      "43\n",
      "10\n",
      "50\n",
      "31\n",
      "84\n",
      "49\n",
      "78\n",
      "24\n",
      "68\n",
      "98\n",
      "58\n",
      "51\n",
      "93\n",
      "36\n",
      "74\n",
      "78\n",
      "55\n",
      "50\n",
      "25\n",
      "65\n",
      "86\n",
      "35\n",
      "33\n",
      "92\n",
      "37\n",
      "71\n",
      "61\n",
      "5\n",
      "79\n",
      "71\n",
      "20\n",
      "59\n",
      "28\n",
      "76\n",
      "31\n",
      "50\n",
      "62\n",
      "9\n",
      "4\n",
      "54\n",
      "38\n",
      "11\n",
      "59\n",
      "84\n",
      "63\n",
      "66\n",
      "35\n",
      "52\n",
      "73\n",
      "87\n",
      "62\n",
      "15\n",
      "11\n",
      "59\n",
      "20\n",
      "47\n",
      "96\n",
      "26\n",
      "36\n",
      "35\n",
      "77\n",
      "38\n",
      "24\n",
      "2\n",
      "17\n",
      "36\n",
      "80\n",
      "74\n",
      "41\n",
      "32\n",
      "76\n",
      "44\n",
      "91\n",
      "21\n",
      "81\n",
      "53\n",
      "55\n",
      "47\n",
      "79\n",
      "19\n",
      "31\n",
      "64\n",
      "49\n",
      "35\n",
      "97\n",
      "58\n",
      "43\n",
      "20\n",
      "86\n",
      "22\n",
      "32\n",
      "18\n",
      "53\n",
      "60\n",
      "36\n",
      "83\n",
      "18\n",
      "32\n",
      "66\n",
      "99\n",
      "51\n",
      "35\n",
      "69\n",
      "11\n",
      "22\n",
      "49\n",
      "21\n",
      "93\n",
      "1\n",
      "55\n",
      "51\n",
      "55\n",
      "51\n",
      "67\n",
      "76\n",
      "52\n",
      "31\n",
      "82\n",
      "75\n",
      "61\n",
      "55\n",
      "90\n",
      "78\n",
      "34\n",
      "87\n",
      "39\n",
      "85\n",
      "70\n",
      "2\n",
      "14\n",
      "45\n",
      "1\n",
      "90\n",
      "64\n",
      "55\n",
      "12\n",
      "91\n",
      "47\n",
      "2\n",
      "99\n",
      "79\n",
      "13\n",
      "8\n",
      "84\n",
      "27\n",
      "11\n",
      "71\n",
      "21\n",
      "8\n",
      "55\n",
      "75\n",
      "40\n",
      "17\n",
      "4\n",
      "63\n",
      "51\n",
      "48\n",
      "65\n",
      "6\n",
      "39\n",
      "39\n",
      "42\n",
      "49\n",
      "14\n",
      "83\n",
      "23\n",
      "78\n",
      "47\n",
      "81\n",
      "41\n",
      "76\n",
      "99\n",
      "97\n",
      "24\n",
      "24\n",
      "76\n",
      "57\n",
      "16\n",
      "44\n",
      "54\n",
      "92\n",
      "30\n",
      "4\n",
      "2\n",
      "1\n",
      "39\n",
      "98\n",
      "90\n",
      "74\n",
      "81\n",
      "74\n",
      "64\n",
      "42\n",
      "59\n",
      "69\n",
      "67\n",
      "66\n",
      "10\n",
      "52\n",
      "22\n",
      "11\n",
      "69\n",
      "39\n",
      "15\n",
      "77\n",
      "36\n",
      "41\n",
      "94\n",
      "45\n",
      "17\n",
      "14\n",
      "62\n",
      "4\n",
      "37\n",
      "13\n",
      "77\n",
      "69\n",
      "72\n",
      "22\n",
      "75\n",
      "45\n",
      "3\n",
      "8\n",
      "24\n",
      "28\n",
      "57\n",
      "10\n",
      "2\n",
      "0\n",
      "89\n",
      "7\n",
      "94\n",
      "68\n",
      "66\n",
      "17\n",
      "5\n",
      "90\n",
      "77\n",
      "34\n",
      "77\n",
      "26\n",
      "35\n",
      "52\n",
      "70\n",
      "29\n",
      "94\n",
      "37\n",
      "83\n",
      "40\n",
      "0\n",
      "92\n",
      "96\n",
      "4\n",
      "78\n",
      "80\n",
      "6\n",
      "85\n",
      "96\n",
      "8\n",
      "70\n",
      "62\n",
      "25\n",
      "22\n",
      "1\n",
      "82\n",
      "93\n",
      "82\n",
      "96\n",
      "70\n",
      "8\n",
      "67\n",
      "4\n",
      "86\n",
      "19\n",
      "17\n",
      "32\n",
      "38\n",
      "57\n",
      "84\n",
      "10\n",
      "40\n",
      "12\n",
      "33\n",
      "94\n",
      "68\n",
      "8\n",
      "89\n",
      "69\n",
      "43\n",
      "60\n",
      "11\n",
      "0\n",
      "12\n",
      "90\n",
      "2\n",
      "54\n",
      "45\n",
      "65\n",
      "50\n",
      "3\n",
      "68\n",
      "17\n",
      "35\n",
      "81\n",
      "32\n",
      "99\n",
      "77\n",
      "84\n",
      "22\n",
      "30\n",
      "23\n",
      "36\n",
      "73\n",
      "80\n",
      "92\n",
      "31\n",
      "9\n",
      "86\n",
      "26\n",
      "85\n",
      "30\n",
      "12\n",
      "54\n",
      "39\n",
      "76\n",
      "45\n",
      "51\n",
      "57\n",
      "19\n",
      "48\n",
      "81\n",
      "55\n",
      "38\n",
      "27\n",
      "54\n",
      "81\n",
      "84\n",
      "0\n",
      "64\n",
      "77\n",
      "52\n",
      "82\n",
      "12\n",
      "89\n",
      "53\n",
      "21\n",
      "18\n",
      "36\n",
      "44\n",
      "35\n",
      "31\n",
      "62\n",
      "41\n",
      "65\n",
      "28\n",
      "20\n",
      "21\n",
      "86\n",
      "72\n",
      "18\n",
      "88\n",
      "76\n",
      "71\n",
      "48\n",
      "12\n",
      "45\n",
      "60\n",
      "99\n",
      "84\n",
      "24\n",
      "37\n",
      "86\n",
      "76\n",
      "84\n",
      "51\n",
      "60\n",
      "97\n",
      "29\n",
      "65\n",
      "88\n",
      "83\n",
      "96\n",
      "53\n",
      "32\n",
      "79\n",
      "87\n",
      "33\n",
      "46\n",
      "22\n",
      "38\n",
      "47\n",
      "24\n",
      "3\n",
      "54\n",
      "85\n",
      "65\n",
      "75\n",
      "80\n",
      "76\n",
      "92\n",
      "84\n",
      "61\n",
      "66\n",
      "39\n",
      "29\n",
      "35\n",
      "64\n",
      "80\n",
      "96\n",
      "89\n",
      "83\n",
      "32\n",
      "1\n",
      "85\n",
      "75\n",
      "9\n",
      "25\n",
      "87\n",
      "59\n",
      "38\n",
      "82\n",
      "27\n",
      "6\n",
      "26\n",
      "34\n",
      "14\n",
      "14\n",
      "46\n",
      "70\n",
      "17\n",
      "84\n",
      "97\n",
      "49\n",
      "69\n",
      "59\n",
      "50\n",
      "86\n",
      "61\n",
      "40\n",
      "66\n",
      "50\n",
      "29\n",
      "49\n",
      "26\n",
      "53\n",
      "73\n",
      "85\n",
      "46\n",
      "81\n",
      "25\n",
      "68\n",
      "71\n",
      "14\n",
      "87\n",
      "37\n",
      "86\n",
      "72\n",
      "28\n",
      "93\n",
      "62\n",
      "72\n",
      "41\n",
      "98\n",
      "51\n",
      "46\n",
      "36\n",
      "20\n",
      "57\n",
      "1\n",
      "96\n",
      "16\n",
      "38\n",
      "85\n",
      "95\n",
      "23\n",
      "14\n",
      "53\n",
      "50\n",
      "2\n",
      "9\n",
      "42\n",
      "21\n",
      "12\n",
      "73\n",
      "29\n",
      "81\n",
      "63\n",
      "64\n",
      "89\n",
      "97\n",
      "63\n",
      "84\n",
      "84\n",
      "6\n",
      "9\n",
      "44\n",
      "7\n",
      "39\n",
      "1\n",
      "68\n",
      "83\n",
      "71\n",
      "69\n",
      "84\n",
      "23\n",
      "51\n",
      "40\n",
      "63\n",
      "17\n",
      "48\n",
      "48\n",
      "2\n",
      "66\n",
      "98\n",
      "44\n",
      "12\n",
      "14\n",
      "56\n",
      "58\n",
      "70\n",
      "85\n",
      "70\n",
      "94\n",
      "41\n",
      "97\n",
      "5\n",
      "15\n",
      "62\n",
      "2\n",
      "58\n",
      "56\n",
      "13\n",
      "72\n",
      "97\n",
      "25\n",
      "87\n",
      "24\n",
      "34\n",
      "93\n",
      "45\n",
      "78\n",
      "68\n",
      "89\n",
      "31\n",
      "73\n",
      "85\n",
      "50\n",
      "95\n",
      "96\n",
      "76\n",
      "32\n",
      "77\n",
      "59\n",
      "84\n",
      "48\n",
      "10\n",
      "32\n",
      "98\n",
      "33\n",
      "69\n",
      "14\n",
      "69\n",
      "36\n",
      "72\n",
      "65\n",
      "94\n",
      "86\n",
      "64\n",
      "16\n",
      "90\n",
      "4\n",
      "96\n",
      "83\n",
      "71\n",
      "51\n",
      "41\n",
      "65\n",
      "61\n",
      "63\n",
      "96\n",
      "62\n",
      "85\n",
      "74\n",
      "57\n",
      "23\n",
      "20\n",
      "38\n",
      "15\n",
      "25\n",
      "72\n",
      "62\n",
      "37\n",
      "62\n",
      "15\n",
      "47\n",
      "75\n",
      "26\n",
      "28\n",
      "27\n",
      "37\n",
      "58\n",
      "46\n",
      "48\n",
      "52\n",
      "79\n",
      "71\n",
      "7\n",
      "60\n",
      "60\n",
      "38\n",
      "49\n",
      "62\n",
      "0\n",
      "19\n",
      "46\n",
      "90\n",
      "5\n",
      "22\n",
      "34\n",
      "75\n",
      "41\n",
      "65\n",
      "51\n",
      "65\n",
      "46\n",
      "1\n",
      "14\n",
      "17\n",
      "65\n",
      "98\n",
      "45\n",
      "14\n",
      "90\n",
      "35\n",
      "30\n",
      "8\n",
      "21\n",
      "18\n",
      "65\n",
      "32\n",
      "34\n",
      "48\n",
      "75\n",
      "29\n",
      "92\n",
      "76\n",
      "30\n",
      "93\n",
      "4\n",
      "37\n",
      "82\n",
      "11\n",
      "54\n",
      "8\n",
      "43\n",
      "67\n",
      "30\n",
      "8\n",
      "40\n",
      "53\n",
      "1\n",
      "93\n",
      "26\n",
      "93\n",
      "6\n",
      "87\n",
      "22\n",
      "91\n",
      "24\n",
      "75\n",
      "34\n",
      "86\n",
      "8\n",
      "8\n",
      "42\n",
      "51\n",
      "94\n",
      "81\n",
      "18\n",
      "85\n",
      "48\n",
      "35\n",
      "20\n",
      "50\n",
      "19\n",
      "55\n",
      "26\n",
      "64\n",
      "78\n",
      "15\n",
      "72\n",
      "93\n",
      "65\n",
      "95\n",
      "87\n",
      "72\n",
      "35\n",
      "27\n",
      "36\n",
      "97\n",
      "73\n",
      "35\n",
      "12\n",
      "24\n",
      "70\n",
      "26\n",
      "71\n",
      "34\n",
      "67\n",
      "20\n",
      "85\n",
      "74\n",
      "99\n",
      "92\n",
      "99\n",
      "21\n",
      "50\n",
      "36\n",
      "82\n",
      "71\n",
      "61\n",
      "23\n",
      "15\n",
      "77\n",
      "40\n",
      "74\n",
      "25\n",
      "19\n",
      "6\n",
      "61\n",
      "68\n",
      "46\n",
      "5\n",
      "10\n",
      "11\n",
      "41\n",
      "55\n",
      "96\n",
      "57\n",
      "30\n",
      "96\n",
      "88\n",
      "72\n",
      "51\n",
      "19\n",
      "40\n",
      "2\n",
      "76\n",
      "54\n",
      "22\n",
      "68\n",
      "70\n",
      "0\n",
      "5\n",
      "42\n",
      "11\n",
      "61\n",
      "88\n",
      "67\n",
      "77\n",
      "34\n",
      "29\n",
      "97\n",
      "13\n",
      "29\n",
      "8\n",
      "15\n",
      "70\n",
      "29\n",
      "19\n",
      "40\n",
      "47\n",
      "8\n",
      "50\n",
      "26\n",
      "89\n",
      "58\n",
      "86\n",
      "85\n",
      "61\n",
      "96\n",
      "75\n",
      "80\n",
      "95\n",
      "17\n",
      "93\n",
      "80\n",
      "53\n",
      "55\n",
      "27\n",
      "40\n",
      "9\n",
      "92\n",
      "87\n",
      "43\n",
      "79\n",
      "52\n",
      "9\n",
      "32\n",
      "42\n",
      "57\n",
      "56\n",
      "99\n",
      "57\n",
      "81\n",
      "9\n",
      "70\n",
      "51\n",
      "50\n",
      "10\n",
      "70\n",
      "40\n",
      "40\n",
      "63\n",
      "50\n",
      "62\n",
      "28\n",
      "94\n",
      "52\n",
      "86\n",
      "98\n",
      "13\n",
      "70\n",
      "9\n",
      "19\n",
      "15\n",
      "68\n",
      "66\n",
      "24\n",
      "63\n",
      "56\n",
      "60\n",
      "12\n",
      "53\n",
      "36\n",
      "98\n",
      "20\n",
      "92\n",
      "24\n",
      "16\n",
      "26\n",
      "12\n",
      "45\n",
      "71\n",
      "61\n",
      "30\n",
      "45\n",
      "75\n",
      "94\n",
      "29\n",
      "48\n",
      "97\n",
      "95\n",
      "12\n",
      "80\n",
      "63\n",
      "85\n",
      "33\n",
      "32\n",
      "46\n",
      "70\n",
      "51\n",
      "8\n",
      "29\n",
      "56\n",
      "11\n",
      "60\n",
      "48\n",
      "21\n",
      "21\n",
      "60\n",
      "56\n",
      "63\n",
      "33\n",
      "79\n",
      "17\n",
      "20\n",
      "16\n",
      "91\n",
      "34\n",
      "14\n",
      "92\n",
      "6\n",
      "89\n",
      "13\n",
      "85\n",
      "96\n",
      "27\n",
      "81\n",
      "63\n",
      "59\n",
      "10\n",
      "78\n",
      "18\n",
      "53\n",
      "17\n",
      "27\n",
      "43\n",
      "61\n",
      "54\n",
      "25\n",
      "79\n",
      "68\n",
      "31\n",
      "69\n",
      "64\n",
      "83\n",
      "41\n",
      "35\n",
      "96\n",
      "20\n",
      "87\n",
      "90\n",
      "52\n",
      "26\n",
      "83\n",
      "67\n",
      "20\n",
      "20\n",
      "7\n",
      "83\n",
      "27\n",
      "45\n",
      "68\n",
      "93\n",
      "86\n",
      "12\n",
      "60\n",
      "73\n",
      "99\n",
      "1\n",
      "80\n",
      "26\n",
      "58\n",
      "88\n",
      "97\n",
      "88\n",
      "19\n",
      "34\n",
      "19\n",
      "13\n",
      "44\n",
      "48\n",
      "58\n",
      "16\n",
      "63\n",
      "80\n",
      "55\n",
      "4\n",
      "32\n",
      "46\n",
      "98\n",
      "32\n",
      "45\n",
      "87\n",
      "97\n",
      "12\n",
      "8\n",
      "45\n",
      "62\n",
      "61\n",
      "89\n",
      "62\n",
      "78\n",
      "83\n",
      "45\n",
      "85\n",
      "37\n",
      "54\n",
      "30\n",
      "7\n",
      "59\n",
      "24\n",
      "94\n",
      "7\n",
      "94\n",
      "94\n",
      "11\n",
      "42\n",
      "65\n",
      "47\n",
      "40\n",
      "38\n",
      "4\n",
      "82\n",
      "46\n",
      "75\n",
      "51\n",
      "74\n",
      "34\n",
      "5\n",
      "85\n",
      "30\n",
      "74\n",
      "22\n",
      "81\n",
      "92\n",
      "91\n",
      "52\n",
      "51\n",
      "44\n",
      "62\n",
      "65\n",
      "76\n",
      "84\n",
      "0\n",
      "43\n",
      "48\n",
      "67\n",
      "62\n",
      "89\n",
      "83\n",
      "18\n",
      "31\n",
      "8\n",
      "68\n",
      "97\n",
      "3\n",
      "83\n",
      "70\n",
      "39\n",
      "0\n",
      "86\n",
      "77\n",
      "58\n",
      "89\n",
      "90\n",
      "81\n",
      "61\n",
      "41\n",
      "80\n",
      "52\n",
      "66\n",
      "68\n",
      "43\n",
      "11\n",
      "25\n",
      "27\n",
      "35\n",
      "88\n",
      "14\n",
      "75\n",
      "53\n",
      "5\n",
      "35\n",
      "90\n",
      "61\n",
      "7\n",
      "91\n",
      "1\n",
      "5\n",
      "17\n",
      "72\n",
      "41\n",
      "94\n",
      "33\n",
      "33\n",
      "39\n",
      "23\n",
      "6\n",
      "31\n",
      "63\n",
      "71\n",
      "67\n",
      "93\n",
      "84\n",
      "46\n",
      "74\n",
      "33\n",
      "77\n",
      "65\n",
      "50\n",
      "98\n",
      "51\n",
      "72\n",
      "36\n",
      "41\n",
      "47\n",
      "54\n",
      "87\n",
      "37\n",
      "75\n",
      "74\n",
      "71\n",
      "14\n",
      "57\n",
      "9\n",
      "44\n",
      "57\n",
      "83\n",
      "45\n",
      "61\n",
      "52\n",
      "63\n",
      "89\n",
      "10\n",
      "85\n",
      "39\n",
      "7\n",
      "25\n",
      "98\n",
      "74\n",
      "70\n",
      "70\n",
      "49\n",
      "70\n",
      "87\n",
      "90\n",
      "15\n",
      "65\n",
      "97\n",
      "36\n",
      "83\n",
      "51\n",
      "32\n",
      "74\n",
      "80\n",
      "2\n",
      "28\n",
      "78\n",
      "40\n",
      "36\n",
      "91\n",
      "99\n",
      "73\n",
      "24\n",
      "83\n",
      "90\n",
      "82\n",
      "24\n",
      "65\n",
      "16\n",
      "40\n",
      "39\n",
      "7\n",
      "31\n",
      "10\n",
      "51\n",
      "96\n",
      "51\n",
      "29\n",
      "66\n",
      "83\n",
      "30\n",
      "84\n",
      "29\n",
      "5\n",
      "10\n",
      "53\n",
      "74\n",
      "72\n",
      "34\n",
      "15\n",
      "44\n",
      "25\n",
      "66\n",
      "10\n",
      "55\n",
      "48\n",
      "95\n",
      "63\n",
      "64\n",
      "77\n",
      "3\n",
      "13\n",
      "18\n",
      "92\n",
      "55\n",
      "13\n",
      "30\n",
      "29\n",
      "91\n",
      "61\n",
      "75\n",
      "58\n",
      "60\n",
      "70\n",
      "46\n",
      "52\n",
      "94\n",
      "89\n",
      "90\n",
      "56\n",
      "57\n",
      "43\n",
      "60\n",
      "45\n",
      "30\n",
      "59\n",
      "78\n",
      "80\n",
      "54\n",
      "83\n",
      "60\n",
      "76\n",
      "18\n",
      "14\n",
      "26\n",
      "81\n",
      "85\n",
      "32\n",
      "63\n",
      "43\n",
      "56\n",
      "87\n",
      "78\n",
      "45\n",
      "99\n",
      "70\n",
      "8\n",
      "12\n",
      "65\n",
      "80\n",
      "58\n",
      "17\n",
      "39\n",
      "53\n",
      "66\n",
      "48\n",
      "25\n",
      "88\n",
      "32\n",
      "97\n",
      "87\n",
      "37\n",
      "40\n",
      "91\n",
      "16\n",
      "27\n",
      "86\n",
      "89\n",
      "5\n",
      "76\n",
      "83\n",
      "74\n",
      "85\n",
      "24\n",
      "93\n",
      "32\n",
      "76\n",
      "45\n",
      "5\n",
      "52\n",
      "46\n",
      "72\n",
      "40\n",
      "58\n",
      "84\n",
      "91\n",
      "38\n",
      "35\n",
      "66\n",
      "25\n",
      "79\n",
      "57\n",
      "23\n",
      "14\n",
      "15\n",
      "86\n",
      "75\n",
      "45\n",
      "6\n",
      "22\n",
      "33\n",
      "76\n",
      "52\n",
      "41\n",
      "90\n",
      "22\n",
      "34\n",
      "45\n",
      "66\n",
      "7\n",
      "95\n",
      "11\n",
      "1\n",
      "23\n",
      "3\n",
      "22\n",
      "5\n",
      "80\n",
      "93\n",
      "27\n",
      "86\n",
      "69\n",
      "53\n",
      "54\n",
      "63\n",
      "18\n",
      "84\n",
      "66\n",
      "8\n",
      "8\n",
      "42\n",
      "62\n",
      "29\n",
      "30\n",
      "73\n",
      "2\n",
      "96\n",
      "39\n",
      "22\n",
      "45\n",
      "83\n",
      "58\n",
      "73\n",
      "18\n",
      "84\n",
      "4\n",
      "5\n",
      "2\n",
      "18\n",
      "23\n",
      "29\n",
      "85\n",
      "34\n",
      "42\n",
      "16\n",
      "86\n",
      "65\n",
      "45\n",
      "97\n",
      "0\n",
      "20\n",
      "46\n",
      "44\n",
      "86\n",
      "92\n",
      "29\n",
      "85\n",
      "82\n",
      "17\n",
      "38\n",
      "58\n",
      "12\n",
      "26\n",
      "54\n",
      "28\n",
      "58\n",
      "79\n",
      "1\n",
      "95\n",
      "10\n",
      "33\n",
      "23\n",
      "91\n",
      "73\n",
      "1\n",
      "1\n",
      "35\n",
      "10\n",
      "88\n",
      "11\n",
      "29\n",
      "0\n",
      "54\n",
      "61\n",
      "20\n",
      "13\n",
      "17\n",
      "53\n",
      "89\n",
      "18\n",
      "81\n",
      "6\n",
      "96\n",
      "41\n",
      "26\n",
      "26\n",
      "25\n",
      "60\n",
      "22\n",
      "73\n",
      "47\n",
      "24\n",
      "18\n",
      "78\n",
      "17\n",
      "7\n",
      "0\n",
      "87\n",
      "26\n",
      "95\n",
      "14\n",
      "18\n",
      "12\n",
      "54\n",
      "21\n",
      "79\n",
      "8\n",
      "43\n",
      "39\n",
      "24\n",
      "40\n",
      "53\n",
      "35\n",
      "21\n",
      "8\n",
      "57\n",
      "33\n",
      "82\n",
      "35\n",
      "5\n",
      "40\n",
      "65\n",
      "22\n",
      "16\n",
      "64\n",
      "57\n",
      "98\n",
      "64\n",
      "88\n",
      "55\n",
      "58\n",
      "27\n",
      "36\n",
      "13\n",
      "91\n",
      "84\n",
      "9\n",
      "5\n",
      "9\n",
      "65\n",
      "85\n",
      "70\n",
      "93\n",
      "2\n",
      "59\n",
      "79\n",
      "70\n",
      "34\n",
      "97\n",
      "86\n",
      "49\n",
      "18\n",
      "55\n",
      "70\n",
      "73\n",
      "38\n",
      "34\n",
      "61\n",
      "69\n",
      "37\n",
      "64\n",
      "24\n",
      "3\n",
      "78\n",
      "74\n",
      "35\n",
      "1\n",
      "84\n",
      "22\n",
      "86\n",
      "13\n",
      "90\n",
      "68\n",
      "60\n",
      "84\n",
      "0\n",
      "34\n",
      "18\n",
      "32\n",
      "92\n",
      "14\n",
      "96\n",
      "35\n",
      "86\n",
      "3\n",
      "89\n",
      "79\n",
      "15\n",
      "66\n",
      "35\n",
      "12\n",
      "41\n",
      "31\n",
      "34\n",
      "93\n",
      "84\n",
      "26\n",
      "74\n",
      "78\n",
      "50\n",
      "57\n",
      "54\n",
      "2\n",
      "95\n",
      "44\n",
      "66\n",
      "60\n",
      "26\n",
      "58\n",
      "82\n",
      "67\n",
      "98\n",
      "89\n",
      "55\n",
      "76\n",
      "60\n",
      "76\n",
      "91\n",
      "37\n",
      "2\n",
      "3\n",
      "62\n",
      "43\n",
      "91\n",
      "48\n",
      "63\n",
      "34\n",
      "56\n",
      "34\n",
      "53\n",
      "3\n",
      "8\n",
      "40\n",
      "44\n",
      "33\n",
      "61\n",
      "60\n",
      "73\n",
      "61\n",
      "26\n",
      "59\n",
      "49\n",
      "92\n",
      "92\n",
      "6\n",
      "72\n",
      "86\n",
      "18\n",
      "20\n",
      "55\n",
      "0\n",
      "85\n",
      "75\n",
      "18\n",
      "74\n",
      "95\n",
      "81\n",
      "58\n",
      "73\n",
      "60\n",
      "21\n",
      "14\n",
      "19\n",
      "87\n",
      "47\n",
      "79\n",
      "90\n",
      "75\n",
      "73\n",
      "15\n",
      "41\n",
      "39\n",
      "99\n",
      "11\n",
      "94\n",
      "45\n",
      "91\n",
      "36\n",
      "77\n",
      "3\n",
      "75\n",
      "92\n",
      "94\n",
      "61\n",
      "38\n",
      "12\n",
      "1\n",
      "0\n",
      "30\n",
      "84\n",
      "98\n",
      "29\n",
      "7\n",
      "18\n",
      "48\n",
      "89\n",
      "91\n",
      "84\n",
      "63\n",
      "62\n",
      "31\n",
      "40\n",
      "55\n",
      "30\n",
      "61\n",
      "86\n",
      "47\n",
      "33\n",
      "11\n",
      "25\n",
      "14\n",
      "28\n",
      "75\n",
      "11\n",
      "81\n",
      "61\n",
      "73\n",
      "79\n",
      "5\n",
      "88\n",
      "56\n",
      "81\n",
      "31\n",
      "84\n",
      "69\n",
      "30\n",
      "6\n",
      "68\n",
      "70\n",
      "12\n",
      "74\n",
      "7\n",
      "21\n",
      "55\n",
      "71\n",
      "5\n",
      "14\n",
      "48\n",
      "18\n",
      "0\n",
      "70\n",
      "38\n",
      "26\n",
      "24\n",
      "69\n",
      "16\n",
      "9\n",
      "42\n",
      "41\n",
      "39\n",
      "27\n",
      "0\n",
      "70\n",
      "85\n",
      "9\n",
      "43\n",
      "79\n",
      "77\n",
      "75\n",
      "74\n",
      "80\n",
      "42\n",
      "67\n",
      "8\n",
      "0\n",
      "36\n",
      "89\n",
      "43\n",
      "46\n",
      "69\n",
      "56\n",
      "42\n",
      "10\n",
      "71\n",
      "98\n",
      "55\n",
      "40\n",
      "16\n",
      "0\n",
      "21\n",
      "2\n",
      "1\n",
      "64\n",
      "52\n",
      "43\n",
      "83\n",
      "65\n",
      "68\n",
      "18\n",
      "1\n",
      "25\n",
      "96\n",
      "46\n",
      "47\n",
      "90\n",
      "2\n",
      "28\n",
      "37\n",
      "61\n",
      "31\n",
      "77\n",
      "4\n",
      "38\n",
      "93\n",
      "28\n",
      "39\n",
      "18\n",
      "41\n",
      "44\n",
      "49\n",
      "1\n",
      "11\n",
      "19\n",
      "91\n",
      "82\n",
      "60\n",
      "34\n",
      "56\n",
      "19\n",
      "32\n",
      "74\n",
      "87\n",
      "99\n",
      "72\n",
      "98\n",
      "8\n",
      "58\n",
      "93\n",
      "87\n",
      "87\n",
      "24\n",
      "35\n",
      "43\n",
      "52\n",
      "33\n",
      "8\n",
      "63\n",
      "26\n",
      "34\n",
      "39\n",
      "97\n",
      "47\n",
      "75\n",
      "33\n",
      "87\n",
      "49\n",
      "46\n",
      "16\n",
      "33\n",
      "76\n",
      "41\n",
      "97\n",
      "8\n",
      "75\n",
      "17\n",
      "80\n",
      "93\n",
      "27\n",
      "4\n",
      "41\n",
      "49\n",
      "30\n",
      "31\n",
      "21\n",
      "77\n",
      "90\n",
      "54\n",
      "87\n",
      "86\n",
      "37\n",
      "47\n",
      "66\n",
      "2\n",
      "73\n",
      "55\n",
      "25\n",
      "62\n",
      "26\n",
      "19\n",
      "28\n",
      "15\n",
      "14\n",
      "59\n",
      "69\n",
      "45\n",
      "39\n",
      "42\n",
      "58\n",
      "49\n",
      "48\n",
      "44\n",
      "71\n",
      "48\n",
      "69\n",
      "9\n",
      "77\n",
      "25\n",
      "35\n",
      "23\n",
      "66\n",
      "66\n",
      "88\n",
      "82\n",
      "1\n",
      "39\n",
      "88\n",
      "93\n",
      "82\n",
      "7\n",
      "17\n",
      "56\n",
      "40\n",
      "70\n",
      "1\n",
      "68\n",
      "59\n",
      "69\n",
      "45\n",
      "16\n",
      "85\n",
      "12\n",
      "99\n",
      "88\n",
      "40\n",
      "68\n",
      "36\n",
      "17\n",
      "13\n",
      "20\n",
      "46\n",
      "75\n",
      "61\n",
      "70\n",
      "58\n",
      "51\n",
      "75\n",
      "73\n",
      "70\n",
      "37\n",
      "28\n",
      "90\n",
      "95\n",
      "88\n",
      "68\n",
      "38\n",
      "95\n",
      "77\n",
      "16\n",
      "58\n",
      "99\n",
      "39\n",
      "17\n",
      "33\n",
      "77\n",
      "63\n",
      "87\n",
      "75\n",
      "4\n",
      "16\n",
      "94\n",
      "55\n",
      "76\n",
      "60\n",
      "97\n",
      "1\n",
      "0\n",
      "75\n",
      "31\n",
      "55\n",
      "71\n",
      "75\n",
      "52\n",
      "6\n",
      "43\n",
      "14\n",
      "84\n",
      "14\n",
      "51\n",
      "1\n",
      "88\n",
      "53\n",
      "66\n",
      "5\n",
      "56\n",
      "32\n",
      "52\n",
      "40\n",
      "24\n",
      "86\n",
      "54\n",
      "54\n",
      "88\n",
      "61\n",
      "87\n",
      "54\n",
      "24\n",
      "10\n",
      "85\n",
      "17\n",
      "90\n",
      "22\n",
      "86\n",
      "77\n",
      "79\n",
      "94\n",
      "45\n",
      "0\n",
      "39\n",
      "89\n",
      "82\n",
      "41\n",
      "87\n",
      "91\n",
      "73\n",
      "62\n",
      "72\n",
      "98\n",
      "10\n",
      "11\n",
      "28\n",
      "38\n",
      "74\n",
      "70\n",
      "13\n",
      "15\n",
      "24\n",
      "76\n",
      "98\n",
      "67\n",
      "79\n",
      "15\n",
      "47\n",
      "47\n",
      "93\n",
      "73\n",
      "13\n",
      "26\n",
      "70\n",
      "60\n",
      "70\n",
      "11\n",
      "82\n",
      "66\n",
      "34\n",
      "6\n",
      "65\n",
      "62\n",
      "74\n",
      "46\n",
      "36\n",
      "88\n",
      "96\n",
      "48\n",
      "79\n",
      "50\n",
      "83\n",
      "66\n",
      "68\n",
      "97\n",
      "64\n",
      "16\n",
      "61\n",
      "16\n",
      "84\n",
      "18\n",
      "29\n",
      "63\n",
      "57\n",
      "9\n",
      "38\n",
      "43\n",
      "74\n",
      "15\n",
      "1\n",
      "67\n",
      "91\n",
      "1\n",
      "84\n",
      "69\n",
      "13\n",
      "10\n",
      "80\n",
      "68\n",
      "30\n",
      "8\n",
      "3\n",
      "13\n",
      "45\n",
      "18\n",
      "20\n",
      "35\n",
      "28\n",
      "93\n",
      "5\n",
      "53\n",
      "34\n",
      "27\n",
      "93\n",
      "18\n",
      "44\n",
      "93\n",
      "37\n",
      "77\n",
      "46\n",
      "31\n",
      "69\n",
      "47\n",
      "57\n",
      "30\n",
      "85\n",
      "80\n",
      "1\n",
      "82\n",
      "45\n",
      "66\n",
      "18\n",
      "58\n",
      "31\n",
      "42\n",
      "23\n",
      "90\n",
      "18\n",
      "83\n",
      "51\n",
      "80\n",
      "23\n",
      "64\n",
      "61\n",
      "40\n",
      "51\n",
      "99\n",
      "28\n",
      "63\n",
      "97\n",
      "78\n",
      "34\n",
      "84\n",
      "13\n",
      "50\n",
      "17\n",
      "28\n",
      "29\n",
      "10\n",
      "57\n",
      "83\n",
      "83\n",
      "53\n",
      "73\n",
      "59\n",
      "82\n",
      "34\n",
      "15\n",
      "68\n",
      "68\n",
      "34\n",
      "75\n",
      "37\n",
      "8\n",
      "94\n",
      "16\n",
      "24\n",
      "21\n",
      "8\n",
      "96\n",
      "53\n",
      "49\n",
      "38\n",
      "85\n",
      "27\n",
      "32\n",
      "96\n",
      "20\n",
      "29\n",
      "43\n",
      "69\n",
      "94\n",
      "26\n",
      "23\n",
      "91\n",
      "34\n",
      "48\n",
      "71\n",
      "53\n",
      "25\n",
      "0\n",
      "57\n",
      "69\n",
      "73\n",
      "27\n",
      "12\n",
      "42\n",
      "61\n",
      "21\n",
      "72\n",
      "88\n",
      "28\n",
      "15\n",
      "24\n",
      "1\n",
      "77\n",
      "5\n",
      "64\n",
      "51\n",
      "52\n",
      "79\n",
      "70\n",
      "46\n",
      "1\n",
      "59\n",
      "87\n",
      "68\n",
      "88\n",
      "76\n",
      "45\n",
      "15\n",
      "79\n",
      "1\n",
      "35\n",
      "94\n",
      "79\n",
      "16\n",
      "49\n",
      "26\n",
      "72\n",
      "60\n",
      "73\n",
      "75\n",
      "5\n",
      "72\n",
      "27\n",
      "67\n",
      "38\n",
      "18\n",
      "45\n",
      "36\n",
      "40\n",
      "96\n",
      "35\n",
      "7\n",
      "85\n",
      "30\n",
      "14\n",
      "51\n",
      "79\n",
      "76\n",
      "99\n",
      "86\n",
      "15\n",
      "29\n",
      "63\n",
      "66\n",
      "62\n",
      "80\n",
      "24\n",
      "57\n",
      "43\n",
      "78\n",
      "33\n",
      "99\n",
      "95\n",
      "93\n",
      "72\n",
      "71\n",
      "77\n",
      "86\n",
      "64\n",
      "4\n",
      "23\n",
      "62\n",
      "50\n",
      "17\n",
      "98\n",
      "21\n",
      "32\n",
      "57\n",
      "99\n",
      "2\n",
      "70\n",
      "94\n",
      "95\n",
      "81\n",
      "96\n",
      "77\n",
      "67\n",
      "31\n",
      "60\n",
      "74\n",
      "63\n",
      "62\n",
      "36\n",
      "12\n",
      "47\n",
      "75\n",
      "77\n",
      "29\n",
      "94\n",
      "27\n",
      "70\n",
      "32\n",
      "38\n",
      "37\n",
      "2\n",
      "65\n",
      "40\n",
      "53\n",
      "87\n",
      "95\n",
      "53\n",
      "43\n",
      "89\n",
      "69\n",
      "93\n",
      "81\n",
      "84\n",
      "71\n",
      "33\n",
      "73\n",
      "75\n",
      "85\n",
      "47\n",
      "97\n",
      "54\n",
      "13\n",
      "24\n",
      "46\n",
      "62\n",
      "92\n",
      "53\n",
      "98\n",
      "66\n",
      "45\n",
      "48\n",
      "94\n",
      "16\n",
      "69\n",
      "60\n",
      "27\n",
      "35\n",
      "59\n",
      "47\n",
      "44\n",
      "57\n",
      "4\n",
      "83\n",
      "89\n",
      "71\n",
      "58\n",
      "52\n",
      "46\n",
      "58\n",
      "98\n",
      "22\n",
      "62\n",
      "47\n",
      "2\n",
      "58\n",
      "77\n",
      "96\n",
      "86\n",
      "33\n",
      "13\n",
      "69\n",
      "97\n",
      "14\n",
      "51\n",
      "2\n",
      "4\n",
      "29\n",
      "58\n",
      "44\n",
      "6\n",
      "81\n",
      "99\n",
      "57\n",
      "88\n",
      "25\n",
      "38\n",
      "71\n",
      "47\n",
      "53\n",
      "48\n",
      "79\n",
      "59\n",
      "29\n",
      "90\n",
      "26\n",
      "81\n",
      "17\n",
      "14\n",
      "69\n",
      "25\n",
      "32\n",
      "39\n",
      "14\n",
      "89\n",
      "67\n",
      "78\n",
      "28\n",
      "98\n",
      "88\n",
      "20\n",
      "3\n",
      "18\n",
      "60\n",
      "48\n",
      "69\n",
      "18\n",
      "41\n",
      "6\n",
      "39\n",
      "44\n",
      "15\n",
      "37\n",
      "57\n",
      "48\n",
      "98\n",
      "89\n",
      "67\n",
      "77\n",
      "38\n",
      "71\n",
      "21\n",
      "96\n",
      "11\n",
      "13\n",
      "84\n",
      "73\n",
      "58\n",
      "73\n",
      "35\n",
      "31\n",
      "83\n",
      "59\n",
      "77\n",
      "50\n",
      "41\n",
      "89\n",
      "19\n",
      "54\n",
      "68\n",
      "9\n",
      "91\n",
      "67\n",
      "19\n",
      "40\n",
      "71\n",
      "57\n",
      "38\n",
      "9\n",
      "3\n",
      "76\n",
      "20\n",
      "60\n",
      "94\n",
      "26\n",
      "72\n",
      "25\n",
      "61\n",
      "36\n",
      "4\n",
      "14\n",
      "61\n",
      "60\n",
      "14\n",
      "62\n",
      "27\n",
      "66\n",
      "16\n",
      "67\n",
      "93\n",
      "23\n",
      "88\n",
      "18\n",
      "58\n",
      "0\n",
      "83\n",
      "85\n",
      "56\n",
      "20\n",
      "45\n",
      "20\n",
      "30\n",
      "96\n",
      "15\n",
      "98\n",
      "51\n",
      "26\n",
      "0\n",
      "47\n",
      "57\n",
      "59\n",
      "10\n",
      "51\n",
      "65\n",
      "23\n",
      "77\n",
      "43\n",
      "15\n",
      "55\n",
      "77\n",
      "19\n",
      "73\n",
      "77\n",
      "7\n",
      "29\n",
      "4\n",
      "61\n",
      "64\n",
      "30\n",
      "39\n",
      "70\n",
      "19\n",
      "51\n",
      "9\n",
      "17\n",
      "28\n",
      "45\n",
      "12\n",
      "83\n",
      "49\n",
      "63\n",
      "71\n",
      "12\n",
      "11\n",
      "77\n",
      "35\n",
      "29\n",
      "40\n",
      "15\n",
      "84\n",
      "19\n",
      "66\n",
      "70\n",
      "62\n",
      "34\n",
      "94\n",
      "72\n",
      "35\n",
      "50\n",
      "99\n",
      "90\n",
      "16\n",
      "56\n",
      "4\n",
      "24\n",
      "60\n",
      "3\n",
      "19\n",
      "14\n",
      "68\n",
      "81\n",
      "61\n",
      "90\n",
      "21\n",
      "57\n",
      "22\n",
      "87\n",
      "12\n",
      "38\n",
      "10\n",
      "93\n",
      "77\n",
      "84\n",
      "41\n",
      "64\n",
      "76\n",
      "25\n",
      "91\n",
      "94\n",
      "42\n",
      "79\n",
      "19\n",
      "76\n",
      "87\n",
      "18\n",
      "51\n",
      "1\n",
      "50\n",
      "37\n",
      "6\n",
      "45\n",
      "23\n",
      "0\n",
      "55\n",
      "91\n",
      "89\n",
      "95\n",
      "48\n",
      "45\n",
      "54\n",
      "69\n",
      "68\n",
      "56\n",
      "94\n",
      "40\n",
      "67\n",
      "71\n",
      "5\n",
      "50\n",
      "60\n",
      "79\n",
      "0\n",
      "44\n",
      "55\n",
      "46\n",
      "2\n",
      "32\n",
      "45\n",
      "69\n",
      "97\n",
      "13\n",
      "30\n",
      "27\n",
      "74\n",
      "8\n",
      "17\n",
      "42\n",
      "11\n",
      "36\n",
      "69\n",
      "57\n",
      "84\n",
      "90\n",
      "85\n",
      "91\n",
      "79\n",
      "76\n",
      "13\n",
      "8\n",
      "92\n",
      "69\n",
      "82\n",
      "7\n",
      "73\n",
      "89\n",
      "32\n",
      "39\n",
      "26\n",
      "80\n",
      "74\n",
      "15\n",
      "74\n",
      "16\n",
      "57\n",
      "94\n",
      "60\n",
      "33\n",
      "83\n",
      "62\n",
      "85\n",
      "48\n",
      "33\n",
      "11\n",
      "5\n",
      "2\n",
      "18\n",
      "75\n",
      "75\n",
      "3\n",
      "72\n",
      "17\n",
      "89\n",
      "70\n",
      "19\n",
      "36\n",
      "77\n",
      "83\n",
      "63\n",
      "2\n",
      "92\n",
      "17\n",
      "98\n",
      "99\n",
      "77\n",
      "56\n",
      "22\n",
      "84\n",
      "14\n",
      "71\n",
      "94\n",
      "44\n",
      "73\n",
      "41\n",
      "96\n",
      "91\n",
      "85\n",
      "43\n",
      "82\n",
      "40\n",
      "97\n",
      "96\n",
      "47\n",
      "22\n",
      "1\n",
      "46\n",
      "78\n",
      "72\n",
      "93\n",
      "85\n",
      "18\n",
      "63\n",
      "65\n",
      "25\n",
      "44\n",
      "2\n",
      "86\n",
      "45\n",
      "59\n",
      "2\n",
      "54\n",
      "11\n",
      "56\n",
      "75\n",
      "47\n",
      "76\n",
      "20\n",
      "48\n",
      "97\n",
      "9\n",
      "45\n",
      "38\n",
      "84\n",
      "36\n",
      "43\n",
      "84\n",
      "18\n",
      "9\n",
      "72\n",
      "38\n",
      "6\n",
      "75\n",
      "15\n",
      "29\n",
      "35\n",
      "25\n",
      "95\n",
      "3\n",
      "58\n",
      "74\n",
      "44\n",
      "83\n",
      "91\n",
      "74\n",
      "86\n",
      "25\n",
      "38\n",
      "58\n",
      "36\n",
      "90\n",
      "8\n",
      "49\n",
      "65\n",
      "95\n",
      "14\n",
      "81\n",
      "0\n",
      "58\n",
      "96\n",
      "1\n",
      "61\n",
      "21\n",
      "60\n",
      "89\n",
      "82\n",
      "10\n",
      "80\n",
      "52\n",
      "65\n",
      "55\n",
      "32\n",
      "77\n",
      "69\n",
      "26\n",
      "79\n",
      "46\n",
      "20\n",
      "38\n",
      "52\n",
      "15\n",
      "7\n",
      "65\n",
      "63\n",
      "96\n",
      "26\n",
      "29\n",
      "3\n",
      "79\n",
      "39\n",
      "30\n",
      "99\n",
      "2\n",
      "8\n",
      "19\n",
      "52\n",
      "69\n",
      "58\n",
      "54\n",
      "82\n",
      "3\n",
      "82\n",
      "93\n",
      "70\n",
      "99\n",
      "21\n",
      "17\n",
      "56\n",
      "64\n",
      "74\n",
      "1\n",
      "62\n",
      "61\n",
      "85\n",
      "78\n",
      "58\n",
      "53\n",
      "74\n",
      "47\n",
      "5\n",
      "34\n",
      "81\n",
      "64\n",
      "77\n",
      "30\n",
      "66\n",
      "4\n",
      "45\n",
      "30\n",
      "98\n",
      "44\n",
      "95\n",
      "87\n",
      "63\n",
      "87\n",
      "26\n",
      "41\n",
      "70\n",
      "22\n",
      "21\n",
      "32\n",
      "90\n",
      "36\n",
      "85\n",
      "74\n",
      "87\n",
      "21\n",
      "87\n",
      "71\n",
      "53\n",
      "27\n",
      "63\n",
      "1\n",
      "8\n",
      "93\n",
      "98\n",
      "61\n",
      "88\n",
      "37\n",
      "10\n",
      "83\n",
      "91\n",
      "85\n",
      "34\n",
      "24\n",
      "49\n",
      "12\n",
      "28\n",
      "74\n",
      "44\n",
      "58\n",
      "45\n",
      "87\n",
      "79\n",
      "32\n",
      "14\n",
      "47\n",
      "77\n",
      "59\n",
      "60\n",
      "71\n",
      "25\n",
      "67\n",
      "81\n",
      "98\n",
      "54\n",
      "17\n",
      "21\n",
      "1\n",
      "88\n",
      "21\n",
      "77\n",
      "12\n",
      "15\n",
      "82\n",
      "22\n",
      "16\n",
      "66\n",
      "25\n",
      "1\n",
      "29\n",
      "29\n",
      "73\n",
      "27\n",
      "81\n",
      "63\n",
      "53\n",
      "23\n",
      "13\n",
      "86\n",
      "44\n",
      "71\n",
      "28\n",
      "75\n",
      "98\n",
      "64\n",
      "79\n",
      "16\n",
      "8\n",
      "77\n",
      "22\n",
      "81\n",
      "87\n",
      "10\n",
      "65\n",
      "62\n",
      "49\n",
      "70\n",
      "57\n",
      "74\n",
      "64\n",
      "40\n",
      "91\n",
      "23\n",
      "13\n",
      "80\n",
      "42\n",
      "46\n",
      "30\n",
      "95\n",
      "35\n",
      "5\n",
      "41\n",
      "36\n",
      "59\n",
      "12\n",
      "43\n",
      "86\n",
      "97\n",
      "53\n",
      "50\n",
      "80\n",
      "61\n",
      "20\n",
      "22\n",
      "57\n",
      "25\n",
      "71\n",
      "55\n",
      "68\n",
      "20\n",
      "33\n",
      "67\n",
      "87\n",
      "16\n",
      "41\n",
      "66\n",
      "44\n",
      "25\n",
      "63\n",
      "1\n",
      "15\n",
      "42\n",
      "85\n",
      "8\n",
      "2\n",
      "5\n",
      "45\n",
      "5\n",
      "71\n",
      "56\n",
      "99\n",
      "73\n",
      "78\n",
      "2\n",
      "76\n",
      "30\n",
      "53\n",
      "81\n",
      "65\n",
      "92\n",
      "11\n",
      "95\n",
      "40\n",
      "30\n",
      "62\n",
      "35\n",
      "23\n",
      "78\n",
      "96\n",
      "67\n",
      "36\n",
      "8\n",
      "15\n",
      "80\n",
      "27\n",
      "60\n",
      "54\n",
      "48\n",
      "16\n",
      "57\n",
      "94\n",
      "30\n",
      "92\n",
      "43\n",
      "62\n",
      "58\n",
      "19\n",
      "23\n",
      "38\n",
      "96\n",
      "95\n",
      "10\n",
      "99\n",
      "86\n",
      "53\n",
      "89\n",
      "11\n",
      "52\n",
      "58\n",
      "54\n",
      "85\n",
      "74\n",
      "72\n",
      "72\n",
      "73\n",
      "43\n",
      "37\n",
      "34\n",
      "47\n",
      "52\n",
      "40\n",
      "53\n",
      "45\n",
      "8\n",
      "83\n",
      "90\n",
      "40\n",
      "53\n",
      "32\n",
      "62\n",
      "89\n",
      "44\n",
      "12\n",
      "4\n",
      "89\n",
      "98\n",
      "78\n",
      "31\n",
      "47\n",
      "9\n",
      "73\n",
      "69\n",
      "36\n",
      "57\n",
      "91\n",
      "37\n",
      "61\n",
      "83\n",
      "69\n",
      "11\n",
      "76\n",
      "31\n",
      "10\n",
      "90\n",
      "98\n",
      "94\n",
      "24\n",
      "39\n",
      "1\n",
      "33\n",
      "29\n",
      "29\n",
      "39\n",
      "15\n",
      "99\n",
      "3\n",
      "41\n",
      "66\n",
      "27\n",
      "45\n",
      "55\n",
      "32\n",
      "5\n",
      "45\n",
      "9\n",
      "72\n",
      "33\n",
      "38\n",
      "40\n",
      "24\n",
      "59\n",
      "65\n",
      "46\n",
      "38\n",
      "23\n",
      "39\n",
      "25\n",
      "97\n",
      "66\n",
      "46\n",
      "52\n",
      "29\n",
      "56\n",
      "98\n",
      "82\n",
      "41\n",
      "38\n",
      "51\n",
      "79\n",
      "19\n",
      "18\n",
      "95\n",
      "64\n",
      "78\n",
      "96\n",
      "49\n",
      "64\n",
      "40\n",
      "36\n",
      "97\n",
      "40\n",
      "45\n",
      "49\n",
      "62\n",
      "10\n",
      "56\n",
      "4\n",
      "77\n",
      "81\n",
      "5\n",
      "87\n",
      "3\n",
      "86\n",
      "89\n",
      "17\n",
      "12\n",
      "80\n",
      "72\n",
      "79\n",
      "67\n",
      "40\n",
      "13\n",
      "98\n",
      "37\n",
      "21\n",
      "76\n",
      "32\n",
      "59\n",
      "49\n",
      "30\n",
      "60\n",
      "80\n",
      "51\n",
      "66\n",
      "87\n",
      "38\n",
      "63\n",
      "53\n",
      "4\n",
      "48\n",
      "24\n",
      "13\n",
      "29\n",
      "84\n",
      "46\n",
      "61\n",
      "24\n",
      "34\n",
      "98\n",
      "45\n",
      "99\n",
      "27\n",
      "51\n",
      "91\n",
      "0\n",
      "72\n",
      "50\n",
      "57\n",
      "4\n",
      "60\n",
      "81\n",
      "86\n",
      "9\n",
      "11\n",
      "92\n",
      "99\n",
      "77\n",
      "57\n",
      "14\n",
      "2\n",
      "70\n",
      "69\n",
      "69\n",
      "32\n",
      "79\n",
      "44\n",
      "58\n",
      "0\n",
      "20\n",
      "7\n",
      "45\n",
      "82\n",
      "79\n",
      "58\n",
      "73\n",
      "58\n",
      "75\n",
      "85\n",
      "55\n",
      "70\n",
      "29\n",
      "97\n",
      "11\n",
      "53\n",
      "37\n",
      "73\n",
      "28\n",
      "86\n",
      "24\n",
      "95\n",
      "1\n",
      "2\n",
      "36\n",
      "59\n",
      "99\n",
      "55\n",
      "85\n",
      "0\n",
      "23\n",
      "64\n",
      "82\n",
      "62\n",
      "31\n",
      "86\n",
      "57\n",
      "72\n",
      "73\n",
      "84\n",
      "85\n",
      "90\n",
      "69\n",
      "82\n",
      "21\n",
      "89\n",
      "68\n",
      "68\n",
      "76\n",
      "31\n",
      "58\n",
      "8\n",
      "37\n",
      "13\n",
      "30\n",
      "78\n",
      "43\n",
      "33\n",
      "99\n",
      "42\n",
      "12\n",
      "92\n",
      "8\n",
      "82\n",
      "78\n",
      "97\n",
      "62\n",
      "74\n",
      "4\n",
      "69\n",
      "29\n",
      "97\n",
      "74\n",
      "56\n",
      "18\n",
      "74\n",
      "3\n",
      "95\n",
      "54\n",
      "53\n",
      "45\n",
      "16\n",
      "73\n",
      "29\n",
      "33\n",
      "6\n",
      "86\n",
      "97\n",
      "9\n",
      "53\n",
      "89\n",
      "18\n",
      "87\n",
      "26\n",
      "49\n",
      "11\n",
      "14\n",
      "65\n",
      "83\n",
      "3\n",
      "27\n",
      "30\n",
      "52\n",
      "74\n",
      "29\n",
      "96\n",
      "90\n",
      "14\n",
      "77\n",
      "65\n",
      "7\n",
      "75\n",
      "27\n",
      "16\n",
      "30\n",
      "83\n",
      "14\n",
      "51\n",
      "70\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11264999999999888, 0.040702702702702265, 0.0078)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(predictions, test_labels, mydata.num_classes, mydata.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: Tiny, num of singleton and composite classes: (200, 10)\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      "### HENN Use the model selected from validation set in Epoch 98:\n"
     ]
    }
   ],
   "source": [
    "from backbones import HENN_EfficientNet, HENN_ResNet50, HENN_VGG16\n",
    "\n",
    "num_singles = mydata.num_classes\n",
    "num_comps = mydata.num_comp\n",
    "print(f\"Data: Tiny, num of singleton and composite classes: {num_singles, num_comps}\")\n",
    "\n",
    "num_classes_both = num_singles + num_comps\n",
    "\n",
    "model_HENN = HENN_EfficientNet(num_classes_both, pretrain=True)\n",
    "device = \"cuda:0\"\n",
    "model_HENN = model_HENN.to(device)\n",
    "base_path_spec_HENN = \"/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN_Results/Tiny/GDD_20_15_10M_ker357_sweep_entrGDD_0906/SEED42_10M_Ker5_sweep_GDDexp101/lr_1e-05_klLam_0.0_EntrLamDir_0.0_EntrLamGDD_0\"\n",
    "saved_path_HENN = os.path.join(base_path_spec_HENN, \"model_uncertainty_gdd.pt\")\n",
    "checkpoint = torch.load(saved_path_HENN, map_location=device)\n",
    "model_HENN.load_state_dict(checkpoint[\"model_state_dict_best\"])\n",
    "print(f\"\\n### HENN Use the model selected from validation set in Epoch {checkpoint['epoch_best']}:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EfficientNetFeat(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            *list(pretrained.network.children())[:-2]\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNetFeat(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dStaticSamePadding(\n",
       "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (2): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (3): Conv2dStaticSamePadding(\n",
       "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (4): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (5): AdaptiveAvgPool2d(output_size=1)\n",
       "    (6): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela = EfficientNetFeat(model_HENN)\n",
    "modela "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 12\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m modela(inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 12\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:244\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "modela(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2dStaticSamePadding(\n",
       "   3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "   (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       " ),\n",
       " BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True),\n",
       " ModuleList(\n",
       "   (0): MBConvBlock(\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (1): MBConvBlock(\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (2): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "       (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (3): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (4): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (5): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (6): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (7): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (8): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "       (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (9): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (10): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (11): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (12): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (13): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (14): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (15): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (16): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (17): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (18): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (19): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (20): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (21): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (22): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (23): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "       (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (24): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       "   (25): MBConvBlock(\n",
       "     (_expand_conv): Conv2dStaticSamePadding(\n",
       "       384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "       2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "       (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "     )\n",
       "     (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_se_reduce): Conv2dStaticSamePadding(\n",
       "       2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_se_expand): Conv2dStaticSamePadding(\n",
       "       96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_project_conv): Conv2dStaticSamePadding(\n",
       "       2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "       (static_padding): Identity()\n",
       "     )\n",
       "     (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "     (_swish): MemoryEfficientSwish()\n",
       "   )\n",
       " ),\n",
       " Conv2dStaticSamePadding(\n",
       "   384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "   (static_padding): Identity()\n",
       " ),\n",
       " BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True),\n",
       " AdaptiveAvgPool2d(output_size=1),\n",
       " Dropout(p=0.3, inplace=False)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_HENN.network.children())[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 11\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model_HENN_feat\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     features \u001b[39m=\u001b[39m model_HENN_feat(train_data[:\u001b[39m10\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device))\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 11\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:244\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "model_HENN_feat = EfficientNetFeat(model_HENN)\n",
    "model_HENN_feat.eval()\n",
    "with torch.no_grad():\n",
    "    features = model_HENN_feat(train_data[:10].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HENN_feat.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = train_data[:10].to(device)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_HENN_feat\u001b[39m.\u001b[39;49mfeatures(tmp)\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:244\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "model_HENN_feat.features(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNetFeat(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dStaticSamePadding(\n",
       "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (2): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (3): Conv2dStaticSamePadding(\n",
       "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (4): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (5): AdaptiveAvgPool2d(output_size=1)\n",
       "    (6): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HENN_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model_HENN_feat.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets_GT, labels) in enumerate(mydata.train_loader):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        targets_GT = targets_GT.to(device, non_blocking=True)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 19\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_HENN_feat(inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 19\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:244\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "model_HENN_feat(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_HENN.network.children())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2dStaticSamePadding(\n",
       "    3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (3): Conv2dStaticSamePadding(\n",
       "    384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (4): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (5): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featt = nn.Sequential(\n",
    "    *list(model_HENN.network.children())[:-3]\n",
    ")\n",
    "featt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb Cell 22\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpdml4/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN/baseline_HierarchicalCls/example_cifar100.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m featt(inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HENN/lib/python3.10/site-packages/torch/nn/modules/module.py:244\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "featt(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1536, 7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = model_HENN.network.extract_features(inputs)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1536*49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (_fc): Linear(in_features=1536, out_features=210, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HENN.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1536, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d(1)\n",
    "output = m(tmp)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1536])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa= output.reshape(64, -1)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HENN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
