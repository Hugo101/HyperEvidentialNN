{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T06:18:39.919768Z",
     "start_time": "2022-12-07T06:07:30.644529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyImageNet...\n",
      "length of parent_to_subclass:  107\n",
      "Total 29 Candidate superclasses: ['n04371563', 'n03419014', 'n04490091', 'n02924116', 'n02858304', 'n04379243', 'n07557434', 'n07611358', 'n07707451', 'n03748162', 'n03259505', 'n02898711', 'n03743902', 'n02796623', 'n09433442', 'n03278248', 'n04438304', 'n04147495', 'n04565375', 'n03880531', 'n02876657', 'n01767661', 'n01772222', 'n01942177', 'n02470325', 'n02370806', 'n02075296', 'n02121808', 'n01844917']\n",
      "Vague classes: ['n03419014']\n",
      "Vague classes nid: [['n02730930', 'n03763968']]\n",
      "Vague classes ids: [[62, 119]]\n",
      "Actual label sets\n",
      " R: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167], [168], [169], [170], [171], [172], [173], [174], [175], [176], [177], [178], [179], [180], [181], [182], [183], [184], [185], [186], [187], [188], [189], [190], [191], [192], [193], [194], [195], [196], [197], [198], [199], [62, 119]]\n",
      "Data splitted. Train, Valid, Test size: (90200, 9800, 10000)\n"
     ]
    }
   ],
   "source": [
    "from common_tools import set_random_seeds\n",
    "from data.tinyImageNet import tinyImageNetVague \n",
    "\n",
    "set_random_seeds(42)\n",
    "\n",
    "data_dir = '/home/cxl173430/data/DATASETS/'\n",
    "batch_size = 64\n",
    "\n",
    "mydata = tinyImageNetVague(\n",
    "            data_dir, \n",
    "            num_comp=1, \n",
    "            batch_size=batch_size,\n",
    "            imagenet_hierarchy_path=data_dir,\n",
    "            duplicate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "labels_truth = []\n",
    "labels_dup = []\n",
    "for i in range(90490):\n",
    "    labels_truth.append(mydata.train_loader.dataset[i][1])\n",
    "    labels_dup.append(mydata.train_loader.dataset[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 451,\n",
       "         1: 451,\n",
       "         2: 451,\n",
       "         3: 451,\n",
       "         4: 451,\n",
       "         5: 451,\n",
       "         6: 451,\n",
       "         7: 451,\n",
       "         8: 451,\n",
       "         9: 451,\n",
       "         10: 451,\n",
       "         11: 451,\n",
       "         12: 451,\n",
       "         13: 451,\n",
       "         14: 451,\n",
       "         15: 451,\n",
       "         16: 451,\n",
       "         17: 451,\n",
       "         18: 451,\n",
       "         19: 451,\n",
       "         20: 451,\n",
       "         21: 451,\n",
       "         22: 451,\n",
       "         23: 451,\n",
       "         24: 451,\n",
       "         25: 451,\n",
       "         26: 451,\n",
       "         27: 451,\n",
       "         28: 451,\n",
       "         29: 451,\n",
       "         30: 451,\n",
       "         31: 451,\n",
       "         32: 451,\n",
       "         33: 451,\n",
       "         34: 451,\n",
       "         35: 451,\n",
       "         36: 451,\n",
       "         37: 451,\n",
       "         38: 451,\n",
       "         39: 451,\n",
       "         40: 451,\n",
       "         41: 451,\n",
       "         42: 451,\n",
       "         43: 451,\n",
       "         44: 451,\n",
       "         45: 451,\n",
       "         46: 451,\n",
       "         47: 451,\n",
       "         48: 451,\n",
       "         49: 451,\n",
       "         50: 451,\n",
       "         51: 451,\n",
       "         52: 451,\n",
       "         53: 451,\n",
       "         54: 451,\n",
       "         55: 451,\n",
       "         56: 451,\n",
       "         57: 451,\n",
       "         58: 451,\n",
       "         59: 451,\n",
       "         60: 451,\n",
       "         61: 451,\n",
       "         62: 599,\n",
       "         63: 451,\n",
       "         64: 451,\n",
       "         65: 451,\n",
       "         66: 451,\n",
       "         67: 451,\n",
       "         68: 451,\n",
       "         69: 451,\n",
       "         70: 451,\n",
       "         71: 451,\n",
       "         72: 451,\n",
       "         73: 451,\n",
       "         74: 451,\n",
       "         75: 451,\n",
       "         76: 451,\n",
       "         77: 451,\n",
       "         78: 451,\n",
       "         79: 451,\n",
       "         80: 451,\n",
       "         81: 451,\n",
       "         82: 451,\n",
       "         83: 451,\n",
       "         84: 451,\n",
       "         85: 451,\n",
       "         86: 451,\n",
       "         87: 451,\n",
       "         88: 451,\n",
       "         89: 451,\n",
       "         90: 451,\n",
       "         91: 451,\n",
       "         92: 451,\n",
       "         93: 451,\n",
       "         94: 451,\n",
       "         95: 451,\n",
       "         96: 451,\n",
       "         97: 451,\n",
       "         98: 451,\n",
       "         99: 451,\n",
       "         100: 451,\n",
       "         101: 451,\n",
       "         102: 451,\n",
       "         103: 451,\n",
       "         104: 451,\n",
       "         105: 451,\n",
       "         106: 451,\n",
       "         107: 451,\n",
       "         108: 451,\n",
       "         109: 451,\n",
       "         110: 451,\n",
       "         111: 451,\n",
       "         112: 451,\n",
       "         113: 451,\n",
       "         114: 451,\n",
       "         115: 451,\n",
       "         116: 451,\n",
       "         117: 451,\n",
       "         118: 451,\n",
       "         119: 593,\n",
       "         120: 451,\n",
       "         121: 451,\n",
       "         122: 451,\n",
       "         123: 451,\n",
       "         124: 451,\n",
       "         125: 451,\n",
       "         126: 451,\n",
       "         127: 451,\n",
       "         128: 451,\n",
       "         129: 451,\n",
       "         130: 451,\n",
       "         131: 451,\n",
       "         132: 451,\n",
       "         133: 451,\n",
       "         134: 451,\n",
       "         135: 451,\n",
       "         136: 451,\n",
       "         137: 451,\n",
       "         138: 451,\n",
       "         139: 451,\n",
       "         140: 451,\n",
       "         141: 451,\n",
       "         142: 451,\n",
       "         143: 451,\n",
       "         144: 451,\n",
       "         145: 451,\n",
       "         146: 451,\n",
       "         147: 451,\n",
       "         148: 451,\n",
       "         149: 451,\n",
       "         150: 451,\n",
       "         151: 451,\n",
       "         152: 451,\n",
       "         153: 451,\n",
       "         154: 451,\n",
       "         155: 451,\n",
       "         156: 451,\n",
       "         157: 451,\n",
       "         158: 451,\n",
       "         159: 451,\n",
       "         160: 451,\n",
       "         161: 451,\n",
       "         162: 451,\n",
       "         163: 451,\n",
       "         164: 451,\n",
       "         165: 451,\n",
       "         166: 451,\n",
       "         167: 451,\n",
       "         168: 451,\n",
       "         169: 451,\n",
       "         170: 451,\n",
       "         171: 451,\n",
       "         172: 451,\n",
       "         173: 451,\n",
       "         174: 451,\n",
       "         175: 451,\n",
       "         176: 451,\n",
       "         177: 451,\n",
       "         178: 451,\n",
       "         179: 451,\n",
       "         180: 451,\n",
       "         181: 451,\n",
       "         182: 451,\n",
       "         183: 451,\n",
       "         184: 451,\n",
       "         185: 451,\n",
       "         186: 451,\n",
       "         187: 451,\n",
       "         188: 451,\n",
       "         189: 451,\n",
       "         190: 451,\n",
       "         191: 451,\n",
       "         192: 451,\n",
       "         193: 451,\n",
       "         194: 451,\n",
       "         195: 451,\n",
       "         196: 451,\n",
       "         197: 451,\n",
       "         198: 451,\n",
       "         199: 451})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cnt_train_truth = Counter(labels_truth)\n",
    "label_cnt_train_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 451,\n",
       "         1: 451,\n",
       "         2: 451,\n",
       "         3: 451,\n",
       "         4: 451,\n",
       "         5: 451,\n",
       "         6: 451,\n",
       "         7: 451,\n",
       "         8: 451,\n",
       "         9: 451,\n",
       "         10: 451,\n",
       "         11: 451,\n",
       "         12: 451,\n",
       "         13: 451,\n",
       "         14: 451,\n",
       "         15: 451,\n",
       "         16: 451,\n",
       "         17: 451,\n",
       "         18: 451,\n",
       "         19: 451,\n",
       "         20: 451,\n",
       "         21: 451,\n",
       "         22: 451,\n",
       "         23: 451,\n",
       "         24: 451,\n",
       "         25: 451,\n",
       "         26: 451,\n",
       "         27: 451,\n",
       "         28: 451,\n",
       "         29: 451,\n",
       "         30: 451,\n",
       "         31: 451,\n",
       "         32: 451,\n",
       "         33: 451,\n",
       "         34: 451,\n",
       "         35: 451,\n",
       "         36: 451,\n",
       "         37: 451,\n",
       "         38: 451,\n",
       "         39: 451,\n",
       "         40: 451,\n",
       "         41: 451,\n",
       "         42: 451,\n",
       "         43: 451,\n",
       "         44: 451,\n",
       "         45: 451,\n",
       "         46: 451,\n",
       "         47: 451,\n",
       "         48: 451,\n",
       "         49: 451,\n",
       "         50: 451,\n",
       "         51: 451,\n",
       "         52: 451,\n",
       "         53: 451,\n",
       "         54: 451,\n",
       "         55: 451,\n",
       "         56: 451,\n",
       "         57: 451,\n",
       "         58: 451,\n",
       "         59: 451,\n",
       "         60: 451,\n",
       "         61: 451,\n",
       "         62: 600,\n",
       "         63: 451,\n",
       "         64: 451,\n",
       "         65: 451,\n",
       "         66: 451,\n",
       "         67: 451,\n",
       "         68: 451,\n",
       "         69: 451,\n",
       "         70: 451,\n",
       "         71: 451,\n",
       "         72: 451,\n",
       "         73: 451,\n",
       "         74: 451,\n",
       "         75: 451,\n",
       "         76: 451,\n",
       "         77: 451,\n",
       "         78: 451,\n",
       "         79: 451,\n",
       "         80: 451,\n",
       "         81: 451,\n",
       "         82: 451,\n",
       "         83: 451,\n",
       "         84: 451,\n",
       "         85: 451,\n",
       "         86: 451,\n",
       "         87: 451,\n",
       "         88: 451,\n",
       "         89: 451,\n",
       "         90: 451,\n",
       "         91: 451,\n",
       "         92: 451,\n",
       "         93: 451,\n",
       "         94: 451,\n",
       "         95: 451,\n",
       "         96: 451,\n",
       "         97: 451,\n",
       "         98: 451,\n",
       "         99: 451,\n",
       "         100: 451,\n",
       "         101: 451,\n",
       "         102: 451,\n",
       "         103: 451,\n",
       "         104: 451,\n",
       "         105: 451,\n",
       "         106: 451,\n",
       "         107: 451,\n",
       "         108: 451,\n",
       "         109: 451,\n",
       "         110: 451,\n",
       "         111: 451,\n",
       "         112: 451,\n",
       "         113: 451,\n",
       "         114: 451,\n",
       "         115: 451,\n",
       "         116: 451,\n",
       "         117: 451,\n",
       "         118: 451,\n",
       "         119: 592,\n",
       "         120: 451,\n",
       "         121: 451,\n",
       "         122: 451,\n",
       "         123: 451,\n",
       "         124: 451,\n",
       "         125: 451,\n",
       "         126: 451,\n",
       "         127: 451,\n",
       "         128: 451,\n",
       "         129: 451,\n",
       "         130: 451,\n",
       "         131: 451,\n",
       "         132: 451,\n",
       "         133: 451,\n",
       "         134: 451,\n",
       "         135: 451,\n",
       "         136: 451,\n",
       "         137: 451,\n",
       "         138: 451,\n",
       "         139: 451,\n",
       "         140: 451,\n",
       "         141: 451,\n",
       "         142: 451,\n",
       "         143: 451,\n",
       "         144: 451,\n",
       "         145: 451,\n",
       "         146: 451,\n",
       "         147: 451,\n",
       "         148: 451,\n",
       "         149: 451,\n",
       "         150: 451,\n",
       "         151: 451,\n",
       "         152: 451,\n",
       "         153: 451,\n",
       "         154: 451,\n",
       "         155: 451,\n",
       "         156: 451,\n",
       "         157: 451,\n",
       "         158: 451,\n",
       "         159: 451,\n",
       "         160: 451,\n",
       "         161: 451,\n",
       "         162: 451,\n",
       "         163: 451,\n",
       "         164: 451,\n",
       "         165: 451,\n",
       "         166: 451,\n",
       "         167: 451,\n",
       "         168: 451,\n",
       "         169: 451,\n",
       "         170: 451,\n",
       "         171: 451,\n",
       "         172: 451,\n",
       "         173: 451,\n",
       "         174: 451,\n",
       "         175: 451,\n",
       "         176: 451,\n",
       "         177: 451,\n",
       "         178: 451,\n",
       "         179: 451,\n",
       "         180: 451,\n",
       "         181: 451,\n",
       "         182: 451,\n",
       "         183: 451,\n",
       "         184: 451,\n",
       "         185: 451,\n",
       "         186: 451,\n",
       "         187: 451,\n",
       "         188: 451,\n",
       "         189: 451,\n",
       "         190: 451,\n",
       "         191: 451,\n",
       "         192: 451,\n",
       "         193: 451,\n",
       "         194: 451,\n",
       "         195: 451,\n",
       "         196: 451,\n",
       "         197: 451,\n",
       "         198: 451,\n",
       "         199: 451})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cnt_train_dup = Counter(labels_dup)\n",
    "label_cnt_train_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599 593\n",
      "600 592\n"
     ]
    }
   ],
   "source": [
    "print(label_cnt_train_truth[62], label_cnt_train_truth[119])\n",
    "print(label_cnt_train_dup[62], label_cnt_train_dup[119])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T06:33:04.014914Z",
     "start_time": "2022-12-07T06:33:04.002040Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "import torch\n",
    "import copy\n",
    "from backbones import HENN_EfficientNet\n",
    "from backbones import EfficientNet_pretrain\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the DNN model which has 0.86 singletonJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T06:33:09.073884Z",
     "start_time": "2022-12-07T06:33:06.074554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_path = \"/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN_Results\"\n",
    "base_path = os.path.join(result_path, \"tiny_baseline_DNN\")\n",
    "saved_path = os.path.join(base_path, \"model_CrossEntropy.pt\")\n",
    "num_singles = 200\n",
    "device = \"cuda:9\"\n",
    "model = EfficientNet_pretrain(num_singles)\n",
    "checkpoint = torch.load(saved_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model_best_from_valid = copy.deepcopy(model)\n",
    "model_best_from_valid.load_state_dict(checkpoint[\"model_state_dict_best\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T06:34:12.984539Z",
     "start_time": "2022-12-07T06:34:12.975867Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(output, labels, R, cutoff, detNN=True):\n",
    "    if detNN:\n",
    "        p_exp = F.softmax(output, dim=1)\n",
    "    else:\n",
    "        alpha = torch.add(output, 1)\n",
    "        alpha_sum = torch.sum(alpha, dim=1)\n",
    "        p_exp = torch.div(alpha, alpha_sum[:, None])\n",
    "    \n",
    "    # Get the predicted labels\n",
    "    predicted_labels = torch.argmax(p_exp, dim=1)\n",
    "    num_singles = output.shape[1]\n",
    "    correct_vague = 0.0\n",
    "    correct_nonvague = 0.0\n",
    "    vague_total = 0\n",
    "    nonvague_total = 0\n",
    "    predSet_or_not = []\n",
    "    selected_idx = []\n",
    "    for i in range(len(labels)):\n",
    "        indices = (p_exp[i] >= cutoff).nonzero(as_tuple=True)[0]\n",
    "        predicted_set = set(indices.tolist())\n",
    "\n",
    "        if len(predicted_set) == 1:\n",
    "            predicted_set = set(R[predicted_labels[i].item()])\n",
    "            predSet_or_not.append(0) # singleton\n",
    "            selected_idx.append(True)\n",
    "        else:\n",
    "            predSet_or_not.append(1)\n",
    "            selected_idx.append(False)\n",
    "\n",
    "        ground_truth_set = set(R[labels[i].item()])\n",
    "        intersect = predicted_set.intersection(ground_truth_set)\n",
    "        union = predicted_set.union(ground_truth_set)\n",
    "        if len(predicted_set) == 1:\n",
    "            correct_nonvague += float(len(intersect)) / len(union)\n",
    "            nonvague_total += 1\n",
    "        else:\n",
    "            correct_vague += float(len(intersect)) / len(union)\n",
    "            vague_total += 1\n",
    "    stat_result = [correct_nonvague, correct_vague, nonvague_total, vague_total]\n",
    "    \n",
    "    predSet_or_not = torch.tensor(predSet_or_not) #1:vague, 0：non-vague\n",
    "    # check precision, recall, f-score for composite classes\n",
    "#     prec_r_f = precision_recall_f_v1(labels, predSet_or_not, num_singles)\n",
    "    return stat_result, selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T06:39:29.172919Z",
     "start_time": "2022-12-07T06:35:16.862109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### selected cutoff: 0.25\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import sampler, random_split, DataLoader\n",
    "test_set = mydata.test_loader.dataset\n",
    "test_loader = DataLoader(test_set, batch_size=1, num_workers=1, pin_memory=True)\n",
    "detNN = True \n",
    "\n",
    "\n",
    "# model = model.to(device)\n",
    "model_best_from_valid = model_best_from_valid.to(device)\n",
    "model = model_best_from_valid\n",
    "\n",
    "R = mydata.R \n",
    "num_singles = 200\n",
    "num_comp = 1 \n",
    "\n",
    "#     cutoff = get_cutoff(model, val_loader, R, device, detNN=detNN)\n",
    "cutoff = 0.25\n",
    "print(f\"### selected cutoff: {cutoff}\")\n",
    "model.eval()\n",
    "outputs_all = []\n",
    "labels_all = []\n",
    "preds_all = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, _, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        preds = output.argmax(dim=1)\n",
    "\n",
    "        outputs_all.append(output)\n",
    "        labels_all.append(labels)\n",
    "        preds_all.append(preds)\n",
    "\n",
    "outputs_all = torch.cat(outputs_all, dim=0)\n",
    "labels_all = torch.cat(labels_all, dim=0)\n",
    "stat_result, selected_idx = calculate_metrics(outputs_all, labels_all, R, cutoff, detNN=detNN)\n",
    "\n",
    "avg_js_nonvague = stat_result[0] / (stat_result[2]+1e-10)\n",
    "avg_js_vague = stat_result[1] / (stat_result[3]+1e-10)\n",
    "overall_js = (stat_result[0] + stat_result[1])/(stat_result[2] + stat_result[3]+1e-10)\n",
    "js_result = [overall_js, avg_js_vague, avg_js_nonvague]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T06:55:46.658161Z",
     "start_time": "2022-12-07T06:55:46.648013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8185499999999918, 0.3465189873417356, 0.8679849756959692]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T05:22:07.745021Z",
     "start_time": "2022-12-07T05:22:07.735518Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select the examples corresponds to 0.86 singletonJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the HENN model which has 0.81 singletonJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T07:05:38.551160Z",
     "start_time": "2022-12-07T07:05:35.644764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_path = \"/home/cxl173430/data/uncertainty_Related/HENN_Git_VScode/HyperEvidentialNN_Results\"\n",
    "base_path = os.path.join(result_path, \"exp4/lambda_1\")\n",
    "saved_path = os.path.join(base_path, \"model_uncertainty_digamma.pt\")\n",
    "\n",
    "device = \"cuda:8\"\n",
    "num_both = 201\n",
    "model = HENN_EfficientNet(num_both)\n",
    "checkpoint = torch.load(saved_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model_best_from_valid = copy.deepcopy(model)\n",
    "model_best_from_valid.load_state_dict(checkpoint[\"model_state_dict_best\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T07:06:33.412336Z",
     "start_time": "2022-12-07T07:06:33.404490Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics_ENN(output, labels, selected_idx, R):\n",
    "    GTs = []\n",
    "    Predicteds = []\n",
    "\n",
    "    correct_vague = 0.0\n",
    "    correct_nonvague = 0.0\n",
    "    vague_total = 0\n",
    "    nonvague_total = 0\n",
    "    corr_selected = 0.\n",
    "    for i in range(len(labels)):\n",
    "        k = labels[i].item()\n",
    "        predicted_set = set(R[torch.argmax(output[i])])\n",
    "        Predicteds.append(predicted_set)\n",
    "\n",
    "        ground_truth_set = set(R[k])\n",
    "        GTs.append(ground_truth_set)\n",
    "        \n",
    "        intersect = predicted_set.intersection(ground_truth_set)\n",
    "        union = predicted_set.union(ground_truth_set)\n",
    "        if len(predicted_set) == 1:\n",
    "            correct_nonvague += float(len(intersect)) / len(union)\n",
    "            nonvague_total += 1\n",
    "        else:\n",
    "            correct_vague += float(len(intersect)) / len(union)\n",
    "            vague_total += 1\n",
    "        if selected_idx[i] == True:\n",
    "            corr_selected += float(len(intersect)) / len(union)\n",
    "    \n",
    "    stat_result = [correct_nonvague, correct_vague, nonvague_total, vague_total] #todo check this with calculate_metric\n",
    "    GT_Pred_res = [GTs, Predicteds]\n",
    "    \n",
    "    selected_num = torch.sum(torch.tensor(selected_idx))\n",
    "    print(\"#selected: \", selected_num)\n",
    "    print(\"### singlJS': \", corr_selected/selected_num)\n",
    "    return stat_result, GT_Pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T07:18:03.159332Z",
     "start_time": "2022-12-07T07:13:47.326873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#selected:  tensor(9052)\n",
      "### singlJS':  tensor(0.8509)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8169999999999918, 0.9999999999968749, 0.8164125200641973]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc_subset(idx, labels_true, labels_pred):\n",
    "    labels_true_subs = labels_true[idx]\n",
    "    labels_pred_subs = labels_pred[idx]\n",
    "    corr_subs = torch.sum(labels_true_subs == labels_pred_subs).item()\n",
    "    acc_subs = corr_subs / len(labels_true_subs)\n",
    "    return acc_subs\n",
    "\n",
    "model_best_from_valid = model_best_from_valid.to(device)\n",
    "model = model_best_from_valid\n",
    "\n",
    "model.eval()\n",
    "outputs_all = []\n",
    "labels_all = []\n",
    "preds_all = []\n",
    "\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, _, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        preds = output.argmax(dim=1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "        outputs_all.append(output)\n",
    "        labels_all.append(labels)\n",
    "        preds_all.append(preds)\n",
    "        \n",
    "\n",
    "outputs_all = torch.cat(outputs_all, dim=0)\n",
    "labels_all = torch.cat(labels_all, dim=0)\n",
    "preds_all = torch.cat(preds_all, dim=0)\n",
    "acc = correct / len(labels_all)\n",
    "\n",
    "# calculate the accuracy among singleton examples\n",
    "# acc of composite examples\n",
    "comp_idx = labels_all > num_singles-1\n",
    "acc_comp = acc_subset(comp_idx, labels_all, preds_all)\n",
    "\n",
    "# acc of singleton examples\n",
    "singl_idx = labels_all < num_singles\n",
    "acc_singl = acc_subset(singl_idx, labels_all, preds_all)\n",
    "\n",
    "stat_result, GT_Pred_res = calculate_metrics_ENN(outputs_all, labels_all, selected_idx, R)\n",
    "\n",
    "avg_js_nonvague = stat_result[0] / (stat_result[2]+1e-10)\n",
    "avg_js_vague = stat_result[1] / (stat_result[3]+1e-10)\n",
    "overall_js = (stat_result[0] + stat_result[1])/(stat_result[2] + stat_result[3]+1e-10)\n",
    "\n",
    "js_result = [overall_js, avg_js_vague, avg_js_nonvague]\n",
    "js_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR100...\n",
      "Files already downloaded and verified\n",
      "/home/cxl173430/DATASETS/cifar100_henn/\n",
      "Hierarchical labels:\n",
      "\n",
      "aquatic_mammals :  ['beaver', 'dolphin', 'otter', 'seal', 'whale']\n",
      "fish :  ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout']\n",
      "flowers :  ['orchid', 'poppy', 'rose', 'sunflower', 'tulip']\n",
      "food_containers :  ['bottle', 'bowl', 'can', 'cup', 'plate']\n",
      "fruit_and_vegetables :  ['apple', 'mushroom', 'orange', 'pear', 'sweet_pepper']\n",
      "household_electrical_devices :  ['clock', 'keyboard', 'lamp', 'telephone', 'television']\n",
      "household_furniture :  ['bed', 'chair', 'couch', 'table', 'wardrobe']\n",
      "insects :  ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach']\n",
      "large_carnivores :  ['bear', 'leopard', 'lion', 'tiger', 'wolf']\n",
      "large_man-made_outdoor_things :  ['bridge', 'castle', 'house', 'road', 'skyscraper']\n",
      "large_natural_outdoor_scenes :  ['cloud', 'forest', 'mountain', 'plain', 'sea']\n",
      "large_omnivores_and_herbivores :  ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo']\n",
      "medium_mammals :  ['fox', 'porcupine', 'possum', 'raccoon', 'skunk']\n",
      "non-insect_invertebrates :  ['crab', 'lobster', 'snail', 'spider', 'worm']\n",
      "people :  ['baby', 'boy', 'girl', 'man', 'woman']\n",
      "reptiles :  ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle']\n",
      "small_mammals :  ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel']\n",
      "trees :  ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree']\n",
      "vehicles_1 :  ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train']\n",
      "vehicles_2 :  ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
      "Total 20 Candidate superclasses: ['aquatic_mammals', 'fish', 'flowers', 'food_containers', 'fruit_and_vegetables', 'household_electrical_devices', 'household_furniture', 'insects', 'large_carnivores', 'large_man-made_outdoor_things', 'large_natural_outdoor_scenes', 'large_omnivores_and_herbivores', 'medium_mammals', 'non-insect_invertebrates', 'people', 'reptiles', 'small_mammals', 'trees', 'vehicles_1', 'vehicles_2']\n",
      "Vague classes: ['people']\n",
      "Vague classes nid: [['woman', 'boy']]\n",
      "Vague classes ids: [[98, 11]]\n",
      "Actual label sets\n",
      " R: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [98, 11]]\n",
      "Data splitted. Train, Valid, Test size: (45100, 4900, 10000)\n"
     ]
    }
   ],
   "source": [
    "from data.cifar100 import CIFAR100Vague \n",
    "\n",
    "data_dir = '/home/cxl173430/DATASETS/'\n",
    "batch_size = 64\n",
    "\n",
    "mydata = CIFAR100Vague(\n",
    "            data_dir, \n",
    "            num_comp=1, \n",
    "            batch_size=batch_size,\n",
    "#             imagenet_hierarchy_path=data_dir,\n",
    "            duplicate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,2,3,4,5])\n",
    "idx = a>3\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([6,7,8,9,0])\n",
    "b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(2)\n",
    "random.sample([1,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample([1,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample([1,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample([1,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "random.sample([1,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "random.sample([1,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d7f76c134df65c5573318e989b45a1c1bdfcc683504c05e694022f95b8f93cf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
